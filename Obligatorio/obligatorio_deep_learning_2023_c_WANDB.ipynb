{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarianoChic09/MSc-ORT-Deep-Learning/blob/main/Obligatorio/obligatorio_deep_learning_2023_c_WANDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-IKUpIRO7_N"
      },
      "source": [
        "![AIRBNB](https://www.stevenridercpa.au/wp-content/uploads/2022/09/airbnb-tax.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvWFGvW6O7_P"
      },
      "source": [
        "# Obligatorio de Deep Learning\n",
        "## Semestre 2 - 2023\n",
        "-------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y230kyNjO7_P"
      },
      "source": [
        "## Problema\n",
        "\n",
        "Se presenta un dataset que contiene información de alojamientos publicados en AirBnB con sus respectivos precios. El tamaño del dataset de train es de 1.5 Gb aproximadamente, y 0.5 Gb el de test. Este cuenta con 84 variables predictoras que se podrán utilizar como consideren adecuado.\n",
        "\n",
        "El objetivo es asignar el precio correcto a los alojamientos listados.\n",
        "\n",
        "Además del dataset se les provee esta notebook conteniendo el script de carga de datos y un modelo baseline que corresponde a una arquitectura feed forward.\n",
        "\n",
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0wbKLG_O7_Q"
      },
      "source": [
        "## Consigna\n",
        "\n",
        "### A) <u>Participación en Competencia Kaggle</u>:\n",
        "El objetivo de este punto es participar en la competencia de Kaggle y obtener como mínimo un Mean Absolute Error inferior a 70 puntos. [->Link a la competencia<-](https://www.kaggle.com/t/69c648e3aa214d1f812bf2314c8d4ffa).\n",
        "\n",
        "### B) <u>Utilización de Grid Search (o equivalente)</u>:\n",
        "Para cumplir con la busqueda de modelos óptimos se debe realizar un grid search lo más abarcativo y metódico posible. Recomendamos enfáticamente [Weights and Biases](https://wandb.ai/site)\n",
        "\n",
        "### C) <u>Se debe a su vez investigar e implementar las siguientes técnicas</u>:\n",
        "#### 1. [Batch Normalization](https://machinelearningmastery.com/how-to-accelerate-learning-of-deep-neural-networks-with-batch-normalization/)\n",
        "#### 2. [Gradient Normalization y/o Gradient Clipping](https://machinelearningmastery.com/how-to-avoid-exploding-gradients-in-neural-networks-with-gradient-clipping/)\n",
        "\n",
        "\n",
        "Además como en todas las tareas se evaluará la prolijidad de la entrega, el preprocesamiento de datos, visualizaciones y exploración de técnicas alternativas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iaoqOjjO7_Q"
      },
      "source": [
        "-------"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TeJvT8iRPC4l",
        "outputId": "4398dd1d-4e66-4d37-e9dd-f5badaeddead",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKSvbcSjO7_Q"
      },
      "source": [
        "## 1. Setup\n",
        "### 1.1 Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/Datasets"
      ],
      "metadata": {
        "id": "Ntv1OfCFPON4",
        "outputId": "42d765a0-6a56-4c00-dd07-5ca7dc066569",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Whcv1sryO7_T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9pbFD39O7_U"
      },
      "source": [
        "### 1.2 Seteo de seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bxFQLSNzO7_U"
      },
      "outputs": [],
      "source": [
        "np.random.seed(117)\n",
        "tf.random.set_seed(117)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-GHRJXAO7_U"
      },
      "source": [
        "## 2. Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bqdM3sv4O7_U"
      },
      "outputs": [],
      "source": [
        "file_path = './obligatorio_DL/public_train_data.csv'\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhKvdfZOO7_U"
      },
      "source": [
        "##  3. Análisis exploratorio de datos\n",
        "### 3.1 Dimensiones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XmmIb2VmO7_V",
        "outputId": "ea05132e-b9e2-4e02-f8bb-90790fb2e51a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(326287, 85)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R60VKhrQO7_V"
      },
      "source": [
        "### 3.2 Obtener información sobre las columnas y tipos de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2Lp-JkqZO7_V",
        "outputId": "1a25c3f2-764a-4c08-dd28-7b883923f13b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 326287 entries, 0 to 326286\n",
            "Data columns (total 85 columns):\n",
            " #   Column                          Non-Null Count   Dtype  \n",
            "---  ------                          --------------   -----  \n",
            " 0   id                              326287 non-null  int64  \n",
            " 1   Last Scraped                    326286 non-null  object \n",
            " 2   Name                            326018 non-null  object \n",
            " 3   Summary                         315651 non-null  object \n",
            " 4   Space                           228792 non-null  object \n",
            " 5   Description                     326188 non-null  object \n",
            " 6   Experiences Offered             326287 non-null  object \n",
            " 7   Neighborhood Overview           192513 non-null  object \n",
            " 8   Notes                           130729 non-null  object \n",
            " 9   Transit                         200649 non-null  object \n",
            " 10  Access                          177108 non-null  object \n",
            " 11  Interaction                     169193 non-null  object \n",
            " 12  House Rules                     195763 non-null  object \n",
            " 13  Thumbnail Url                   264638 non-null  object \n",
            " 14  Medium Url                      264637 non-null  object \n",
            " 15  Picture Url                     325786 non-null  object \n",
            " 16  XL Picture Url                  264638 non-null  object \n",
            " 17  Host ID                         326287 non-null  int64  \n",
            " 18  Host URL                        326287 non-null  object \n",
            " 19  Host Name                       325970 non-null  object \n",
            " 20  Host Since                      325970 non-null  object \n",
            " 21  Host Location                   324801 non-null  object \n",
            " 22  Host About                      195571 non-null  object \n",
            " 23  Host Response Time              250846 non-null  object \n",
            " 24  Host Response Rate              250845 non-null  float64\n",
            " 25  Host Acceptance Rate            27630 non-null   object \n",
            " 26  Host Thumbnail Url              325971 non-null  object \n",
            " 27  Host Picture Url                325971 non-null  object \n",
            " 28  Host Neighbourhood              244207 non-null  object \n",
            " 29  Host Listings Count             325971 non-null  float64\n",
            " 30  Host Total Listings Count       325970 non-null  float64\n",
            " 31  Host Verifications              325751 non-null  object \n",
            " 32  Street                          326287 non-null  object \n",
            " 33  Neighbourhood                   227447 non-null  object \n",
            " 34  Neighbourhood Cleansed          326287 non-null  object \n",
            " 35  Neighbourhood Group Cleansed    68297 non-null   object \n",
            " 36  City                            326004 non-null  object \n",
            " 37  State                           294992 non-null  object \n",
            " 38  Zipcode                         313815 non-null  object \n",
            " 39  Market                          322672 non-null  object \n",
            " 40  Smart Location                  326286 non-null  object \n",
            " 41  Country Code                    326286 non-null  object \n",
            " 42  Country                         326286 non-null  object \n",
            " 43  Latitude                        326287 non-null  float64\n",
            " 44  Longitude                       326287 non-null  float64\n",
            " 45  Property Type                   326280 non-null  object \n",
            " 46  Room Type                       326287 non-null  object \n",
            " 47  Accommodates                    326244 non-null  float64\n",
            " 48  Bathrooms                       325300 non-null  float64\n",
            " 49  Bedrooms                        325873 non-null  float64\n",
            " 50  Beds                            325693 non-null  float64\n",
            " 51  Bed Type                        326287 non-null  object \n",
            " 52  Amenities                       323399 non-null  object \n",
            " 53  Square Feet                     7993 non-null    float64\n",
            " 54  Security Deposit                136142 non-null  float64\n",
            " 55  Cleaning Fee                    208181 non-null  float64\n",
            " 56  Guests Included                 326286 non-null  float64\n",
            " 57  Extra People                    326274 non-null  float64\n",
            " 58  Minimum Nights                  326286 non-null  float64\n",
            " 59  Maximum Nights                  326286 non-null  float64\n",
            " 60  Calendar Updated                326287 non-null  object \n",
            " 61  Has Availability                6249 non-null    object \n",
            " 62  Availability 30                 326286 non-null  float64\n",
            " 63  Availability 60                 326286 non-null  float64\n",
            " 64  Availability 90                 326286 non-null  float64\n",
            " 65  Availability 365                326286 non-null  float64\n",
            " 66  Calendar last Scraped           326286 non-null  object \n",
            " 67  Number of Reviews               326286 non-null  float64\n",
            " 68  First Review                    246983 non-null  object \n",
            " 69  Last Review                     247046 non-null  object \n",
            " 70  Review Scores Rating            243160 non-null  float64\n",
            " 71  Review Scores Accuracy          242584 non-null  float64\n",
            " 72  Review Scores Cleanliness       242732 non-null  float64\n",
            " 73  Review Scores Checkin           242378 non-null  float64\n",
            " 74  Review Scores Communication     242710 non-null  float64\n",
            " 75  Review Scores Location          242423 non-null  float64\n",
            " 76  Review Scores Value             242347 non-null  float64\n",
            " 77  License                         9804 non-null    object \n",
            " 78  Jurisdiction Names              89415 non-null   object \n",
            " 79  Cancellation Policy             326286 non-null  object \n",
            " 80  Calculated host listings count  325689 non-null  float64\n",
            " 81  Reviews per Month               246983 non-null  float64\n",
            " 82  Geolocation                     326287 non-null  object \n",
            " 83  Features                        326092 non-null  object \n",
            " 84  Price                           326287 non-null  float64\n",
            "dtypes: float64(31), int64(2), object(52)\n",
            "memory usage: 211.6+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAdII-pqO7_V"
      },
      "source": [
        "### 3.3 Visualizar las primeras filas del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KtBuUl1TO7_V",
        "outputId": "3d1d08ad-0a47-4a87-b90d-44bd2ba2174d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id Last Scraped                                         Name  \\\n",
              "0   0   2017-05-12  Grand Loft in the heart of historic Antwerp   \n",
              "1   1   2017-05-03             CHARMING, CLEAN & COZY BUNGALOW!   \n",
              "2   2   2017-05-09                          la casa di maurizio   \n",
              "\n",
              "                                             Summary  \\\n",
              "0  Best location for visiting Antwerp!! Beautiful...   \n",
              "1  Very centrally located and less than 15 min fr...   \n",
              "2  nice apartment with view to via veneto , very ...   \n",
              "\n",
              "                                               Space  \\\n",
              "0  Welcome in Antwerp!! The loft is situated on t...   \n",
              "1       Well lit, private entrance with small patio.   \n",
              "2                                                NaN   \n",
              "\n",
              "                                         Description Experiences Offered  \\\n",
              "0  Best location for visiting Antwerp!! Beautiful...                none   \n",
              "1  Very centrally located and less than 15 min fr...                none   \n",
              "2  nice apartment with view to via veneto , very ...                none   \n",
              "\n",
              "                          Neighborhood Overview  \\\n",
              "0                                           NaN   \n",
              "1  Quiet. Pretty tree lined streets, safe area.   \n",
              "2                                           NaN   \n",
              "\n",
              "                                        Notes  \\\n",
              "0                                         NaN   \n",
              "1  Has dining table and high back desk chair.   \n",
              "2                                         NaN   \n",
              "\n",
              "                                             Transit  ...  \\\n",
              "0                                                NaN  ...   \n",
              "1  Uber, bus line and metro link is less than 5 m...  ...   \n",
              "2                                                NaN  ...   \n",
              "\n",
              "  Review Scores Location Review Scores Value License       Jurisdiction Names  \\\n",
              "0                   10.0                 9.0     NaN                      NaN   \n",
              "1                    NaN                 NaN     NaN  City of Los Angeles, CA   \n",
              "2                    NaN                 NaN     NaN                      NaN   \n",
              "\n",
              "  Cancellation Policy Calculated host listings count Reviews per Month  \\\n",
              "0              strict                            2.0               2.6   \n",
              "1            flexible                            1.0               NaN   \n",
              "2        flexible_new                            1.0               NaN   \n",
              "\n",
              "                             Geolocation  \\\n",
              "0  51.21938762207894, 4.4034442505151885   \n",
              "1  34.1892692286356, -118.41993491931177   \n",
              "2  41.90859623057272, 12.493518028459327   \n",
              "\n",
              "                                 Features  Price  \n",
              "0   Host Has Profile Pic,Instant Bookable  159.0  \n",
              "1  Host Has Profile Pic,Is Location Exact   49.0  \n",
              "2  Host Has Profile Pic,Is Location Exact   75.0  \n",
              "\n",
              "[3 rows x 85 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0819ea7-688f-4701-91ca-f505342a4aa8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Last Scraped</th>\n",
              "      <th>Name</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Space</th>\n",
              "      <th>Description</th>\n",
              "      <th>Experiences Offered</th>\n",
              "      <th>Neighborhood Overview</th>\n",
              "      <th>Notes</th>\n",
              "      <th>Transit</th>\n",
              "      <th>...</th>\n",
              "      <th>Review Scores Location</th>\n",
              "      <th>Review Scores Value</th>\n",
              "      <th>License</th>\n",
              "      <th>Jurisdiction Names</th>\n",
              "      <th>Cancellation Policy</th>\n",
              "      <th>Calculated host listings count</th>\n",
              "      <th>Reviews per Month</th>\n",
              "      <th>Geolocation</th>\n",
              "      <th>Features</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2017-05-12</td>\n",
              "      <td>Grand Loft in the heart of historic Antwerp</td>\n",
              "      <td>Best location for visiting Antwerp!! Beautiful...</td>\n",
              "      <td>Welcome in Antwerp!! The loft is situated on t...</td>\n",
              "      <td>Best location for visiting Antwerp!! Beautiful...</td>\n",
              "      <td>none</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>strict</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>51.21938762207894, 4.4034442505151885</td>\n",
              "      <td>Host Has Profile Pic,Instant Bookable</td>\n",
              "      <td>159.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2017-05-03</td>\n",
              "      <td>CHARMING, CLEAN &amp; COZY BUNGALOW!</td>\n",
              "      <td>Very centrally located and less than 15 min fr...</td>\n",
              "      <td>Well lit, private entrance with small patio.</td>\n",
              "      <td>Very centrally located and less than 15 min fr...</td>\n",
              "      <td>none</td>\n",
              "      <td>Quiet. Pretty tree lined streets, safe area.</td>\n",
              "      <td>Has dining table and high back desk chair.</td>\n",
              "      <td>Uber, bus line and metro link is less than 5 m...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>City of Los Angeles, CA</td>\n",
              "      <td>flexible</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34.1892692286356, -118.41993491931177</td>\n",
              "      <td>Host Has Profile Pic,Is Location Exact</td>\n",
              "      <td>49.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2017-05-09</td>\n",
              "      <td>la casa di maurizio</td>\n",
              "      <td>nice apartment with view to via veneto , very ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>nice apartment with view to via veneto , very ...</td>\n",
              "      <td>none</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>flexible_new</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>41.90859623057272, 12.493518028459327</td>\n",
              "      <td>Host Has Profile Pic,Is Location Exact</td>\n",
              "      <td>75.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 85 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0819ea7-688f-4701-91ca-f505342a4aa8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b0819ea7-688f-4701-91ca-f505342a4aa8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b0819ea7-688f-4701-91ca-f505342a4aa8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bb44b904-4a5e-4707-9a2a-48d94421d06b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb44b904-4a5e-4707-9a2a-48d94421d06b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bb44b904-4a5e-4707-9a2a-48d94421d06b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBWWhtzoO7_V"
      },
      "source": [
        "### 3.4 Estadísticas descriptivas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0qEeGOEMO7_V",
        "outputId": "2c373881-9f5a-43b6-f35b-1233b4e518f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  id       Host ID  Host Response Rate  Host Listings Count  \\\n",
              "count  326287.000000  3.262870e+05       250845.000000        325971.000000   \n",
              "mean   163143.000000  3.236757e+07           93.408264             9.586000   \n",
              "std     94191.087979  3.174572e+07           17.536835            57.399711   \n",
              "min         0.000000  1.900000e+01            0.000000             0.000000   \n",
              "25%     81571.500000  6.869780e+06           98.000000             1.000000   \n",
              "50%    163143.000000  2.186737e+07          100.000000             1.000000   \n",
              "75%    244714.500000  4.799166e+07          100.000000             3.000000   \n",
              "max    326286.000000  1.350885e+08          100.000000          1114.000000   \n",
              "\n",
              "       Host Total Listings Count       Latitude      Longitude   Accommodates  \\\n",
              "count              325970.000000  326287.000000  326287.000000  326244.000000   \n",
              "mean                    9.586026      38.042816     -15.323924       3.270764   \n",
              "std                    57.399797      22.910029      70.101677       2.037446   \n",
              "min                     0.000000     -38.224427    -123.218712       1.000000   \n",
              "25%                     1.000000      38.923154     -73.968081       2.000000   \n",
              "50%                     1.000000      42.304549       0.090277       2.000000   \n",
              "75%                     3.000000      50.863658      12.342749       4.000000   \n",
              "max                  1114.000000      55.994889     153.637837      18.000000   \n",
              "\n",
              "           Bathrooms       Bedrooms  ...  Review Scores Rating  \\\n",
              "count  325300.000000  325873.000000  ...         243160.000000   \n",
              "mean        1.239482       1.358072  ...             92.880063   \n",
              "std         0.574784       0.921763  ...              8.569521   \n",
              "min         0.000000       0.000000  ...             20.000000   \n",
              "25%         1.000000       1.000000  ...             90.000000   \n",
              "50%         1.000000       1.000000  ...             95.000000   \n",
              "75%         1.000000       2.000000  ...            100.000000   \n",
              "max         8.000000      96.000000  ...            100.000000   \n",
              "\n",
              "       Review Scores Accuracy  Review Scores Cleanliness  \\\n",
              "count           242584.000000              242732.000000   \n",
              "mean                 9.524713                   9.326067   \n",
              "std                  0.855361                   1.038858   \n",
              "min                  2.000000                   2.000000   \n",
              "25%                  9.000000                   9.000000   \n",
              "50%                 10.000000                  10.000000   \n",
              "75%                 10.000000                  10.000000   \n",
              "max                 10.000000                  10.000000   \n",
              "\n",
              "       Review Scores Checkin  Review Scores Communication  \\\n",
              "count          242378.000000                242710.000000   \n",
              "mean                9.691416                     9.708253   \n",
              "std                 0.731702                     0.723143   \n",
              "min                 2.000000                     2.000000   \n",
              "25%                10.000000                    10.000000   \n",
              "50%                10.000000                    10.000000   \n",
              "75%                10.000000                    10.000000   \n",
              "max                10.000000                    10.000000   \n",
              "\n",
              "       Review Scores Location  Review Scores Value  \\\n",
              "count           242423.000000        242347.000000   \n",
              "mean                 9.468215             9.321031   \n",
              "std                  0.805116             0.906478   \n",
              "min                  2.000000             2.000000   \n",
              "25%                  9.000000             9.000000   \n",
              "50%                 10.000000            10.000000   \n",
              "75%                 10.000000            10.000000   \n",
              "max                 10.000000            10.000000   \n",
              "\n",
              "       Calculated host listings count  Reviews per Month          Price  \n",
              "count                   325689.000000      246983.000000  326287.000000  \n",
              "mean                         6.881531           1.486211     138.229041  \n",
              "std                         42.025986           1.752082     149.790527  \n",
              "min                          1.000000           0.010000       0.000000  \n",
              "25%                          1.000000           0.320000      55.000000  \n",
              "50%                          1.000000           0.890000      90.000000  \n",
              "75%                          2.000000           2.040000     150.000000  \n",
              "max                        752.000000         223.000000     999.000000  \n",
              "\n",
              "[8 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72ae8580-d54e-44a8-bf6c-429d616284e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Host ID</th>\n",
              "      <th>Host Response Rate</th>\n",
              "      <th>Host Listings Count</th>\n",
              "      <th>Host Total Listings Count</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Accommodates</th>\n",
              "      <th>Bathrooms</th>\n",
              "      <th>Bedrooms</th>\n",
              "      <th>...</th>\n",
              "      <th>Review Scores Rating</th>\n",
              "      <th>Review Scores Accuracy</th>\n",
              "      <th>Review Scores Cleanliness</th>\n",
              "      <th>Review Scores Checkin</th>\n",
              "      <th>Review Scores Communication</th>\n",
              "      <th>Review Scores Location</th>\n",
              "      <th>Review Scores Value</th>\n",
              "      <th>Calculated host listings count</th>\n",
              "      <th>Reviews per Month</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>326287.000000</td>\n",
              "      <td>3.262870e+05</td>\n",
              "      <td>250845.000000</td>\n",
              "      <td>325971.000000</td>\n",
              "      <td>325970.000000</td>\n",
              "      <td>326287.000000</td>\n",
              "      <td>326287.000000</td>\n",
              "      <td>326244.000000</td>\n",
              "      <td>325300.000000</td>\n",
              "      <td>325873.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>243160.000000</td>\n",
              "      <td>242584.000000</td>\n",
              "      <td>242732.000000</td>\n",
              "      <td>242378.000000</td>\n",
              "      <td>242710.000000</td>\n",
              "      <td>242423.000000</td>\n",
              "      <td>242347.000000</td>\n",
              "      <td>325689.000000</td>\n",
              "      <td>246983.000000</td>\n",
              "      <td>326287.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>163143.000000</td>\n",
              "      <td>3.236757e+07</td>\n",
              "      <td>93.408264</td>\n",
              "      <td>9.586000</td>\n",
              "      <td>9.586026</td>\n",
              "      <td>38.042816</td>\n",
              "      <td>-15.323924</td>\n",
              "      <td>3.270764</td>\n",
              "      <td>1.239482</td>\n",
              "      <td>1.358072</td>\n",
              "      <td>...</td>\n",
              "      <td>92.880063</td>\n",
              "      <td>9.524713</td>\n",
              "      <td>9.326067</td>\n",
              "      <td>9.691416</td>\n",
              "      <td>9.708253</td>\n",
              "      <td>9.468215</td>\n",
              "      <td>9.321031</td>\n",
              "      <td>6.881531</td>\n",
              "      <td>1.486211</td>\n",
              "      <td>138.229041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>94191.087979</td>\n",
              "      <td>3.174572e+07</td>\n",
              "      <td>17.536835</td>\n",
              "      <td>57.399711</td>\n",
              "      <td>57.399797</td>\n",
              "      <td>22.910029</td>\n",
              "      <td>70.101677</td>\n",
              "      <td>2.037446</td>\n",
              "      <td>0.574784</td>\n",
              "      <td>0.921763</td>\n",
              "      <td>...</td>\n",
              "      <td>8.569521</td>\n",
              "      <td>0.855361</td>\n",
              "      <td>1.038858</td>\n",
              "      <td>0.731702</td>\n",
              "      <td>0.723143</td>\n",
              "      <td>0.805116</td>\n",
              "      <td>0.906478</td>\n",
              "      <td>42.025986</td>\n",
              "      <td>1.752082</td>\n",
              "      <td>149.790527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.900000e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-38.224427</td>\n",
              "      <td>-123.218712</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>81571.500000</td>\n",
              "      <td>6.869780e+06</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>38.923154</td>\n",
              "      <td>-73.968081</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>55.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>163143.000000</td>\n",
              "      <td>2.186737e+07</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>42.304549</td>\n",
              "      <td>0.090277</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.890000</td>\n",
              "      <td>90.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>244714.500000</td>\n",
              "      <td>4.799166e+07</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>50.863658</td>\n",
              "      <td>12.342749</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.040000</td>\n",
              "      <td>150.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>326286.000000</td>\n",
              "      <td>1.350885e+08</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1114.000000</td>\n",
              "      <td>1114.000000</td>\n",
              "      <td>55.994889</td>\n",
              "      <td>153.637837</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>752.000000</td>\n",
              "      <td>223.000000</td>\n",
              "      <td>999.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72ae8580-d54e-44a8-bf6c-429d616284e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-72ae8580-d54e-44a8-bf6c-429d616284e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-72ae8580-d54e-44a8-bf6c-429d616284e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4947e345-6718-417a-a529-9d6068cea7f0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4947e345-6718-417a-a529-9d6068cea7f0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4947e345-6718-417a-a529-9d6068cea7f0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LkP5LYdtO7_W",
        "outputId": "4c02c390-001b-4442-e921-5fdb5d07810a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'Last Scraped', 'Name', 'Summary', 'Space', 'Description',\n",
              "       'Experiences Offered', 'Neighborhood Overview', 'Notes', 'Transit',\n",
              "       'Access', 'Interaction', 'House Rules', 'Thumbnail Url', 'Medium Url',\n",
              "       'Picture Url', 'XL Picture Url', 'Host ID', 'Host URL', 'Host Name',\n",
              "       'Host Since', 'Host Location', 'Host About', 'Host Response Time',\n",
              "       'Host Response Rate', 'Host Acceptance Rate', 'Host Thumbnail Url',\n",
              "       'Host Picture Url', 'Host Neighbourhood', 'Host Listings Count',\n",
              "       'Host Total Listings Count', 'Host Verifications', 'Street',\n",
              "       'Neighbourhood', 'Neighbourhood Cleansed',\n",
              "       'Neighbourhood Group Cleansed', 'City', 'State', 'Zipcode', 'Market',\n",
              "       'Smart Location', 'Country Code', 'Country', 'Latitude', 'Longitude',\n",
              "       'Property Type', 'Room Type', 'Accommodates', 'Bathrooms', 'Bedrooms',\n",
              "       'Beds', 'Bed Type', 'Amenities', 'Square Feet', 'Security Deposit',\n",
              "       'Cleaning Fee', 'Guests Included', 'Extra People', 'Minimum Nights',\n",
              "       'Maximum Nights', 'Calendar Updated', 'Has Availability',\n",
              "       'Availability 30', 'Availability 60', 'Availability 90',\n",
              "       'Availability 365', 'Calendar last Scraped', 'Number of Reviews',\n",
              "       'First Review', 'Last Review', 'Review Scores Rating',\n",
              "       'Review Scores Accuracy', 'Review Scores Cleanliness',\n",
              "       'Review Scores Checkin', 'Review Scores Communication',\n",
              "       'Review Scores Location', 'Review Scores Value', 'License',\n",
              "       'Jurisdiction Names', 'Cancellation Policy',\n",
              "       'Calculated host listings count', 'Reviews per Month', 'Geolocation',\n",
              "       'Features', 'Price'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bert Fin"
      ],
      "metadata": {
        "id": "KqfnLuO8t0fT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "Wedud4uTQtiZ",
        "outputId": "35c53eae-baf5-4a05-bda5-cdba721be38b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(326287, 85)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columnas_con_NaNs_mayores_a_50_porciento = df.columns[df.isnull().sum() > 0.5*df.shape[0]]\n",
        "columnas_con_NaNs_mayores_a_50_porciento"
      ],
      "metadata": {
        "id": "39pwwdfNQnY-",
        "outputId": "7c65b1f1-f6ae-4341-b34b-21fcc1f6b831",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Notes', 'Host Acceptance Rate', 'Neighbourhood Group Cleansed',\n",
              "       'Square Feet', 'Security Deposit', 'Has Availability', 'License',\n",
              "       'Jurisdiction Names'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zodYOpYRO7_W"
      },
      "source": [
        "## 4. Modelo Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq-FmVUKO7_W"
      },
      "source": [
        "### 4.1 Seleccionar características relevantes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_columns = list(columnas_con_NaNs_mayores_a_50_porciento)\n",
        "drop_columns.extend(['Host ID','Host URL','Price']) # Dropeo algunas columnas que no tienen sentido como el ID y el URL del host\n",
        "drop_columns"
      ],
      "metadata": {
        "id": "C0mY3hNkRw1y",
        "outputId": "0d546813-56c4-423e-dd97-13a299e7ad8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Notes',\n",
              " 'Host Acceptance Rate',\n",
              " 'Neighbourhood Group Cleansed',\n",
              " 'Square Feet',\n",
              " 'Security Deposit',\n",
              " 'Has Availability',\n",
              " 'License',\n",
              " 'Jurisdiction Names',\n",
              " 'Host ID',\n",
              " 'Host URL',\n",
              " 'Price']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hM5ha5jvO7_W"
      },
      "outputs": [],
      "source": [
        "# features = ['Bathrooms', 'Bedrooms']  # Reemplaza con las características relevantes\n",
        "features = df.columns.drop(drop_columns)\n",
        "target = 'Price'\n",
        "df = df[[*features, target]]\n",
        "# df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "df_train = df.drop('Price',axis=1)\n",
        "numerical_cols = df_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "\n",
        "unique_counts = df_train.drop(numerical_cols,axis=1).nunique()\n",
        "\n",
        "# Calculo las filas que tienen una\n",
        "mean_string_length = df.apply(lambda col: col.dropna().astype(str).apply(len).mean())\n",
        "\n",
        "# Define los límites\n",
        "unique_value_limit = 20  # Por ejemplo, considera una columna categórica si tiene menos de 10 valores únicos\n",
        "string_length_limit = 20  # Por ejemplo, considera una columna de texto si la longitud media de la cadena es mayor que 20\n",
        "\n",
        "# Identifica las columnas categóricas y de texto\n",
        "categorical_cols = unique_counts[(unique_counts < unique_value_limit) & (mean_string_length < string_length_limit)].index.tolist()\n",
        "text_cols = unique_counts[(unique_counts >= unique_value_limit) | (mean_string_length >= string_length_limit)].index.tolist()\n",
        "\n",
        "# df['combined_text'] = df[text_cols].apply(lambda x: ' '.join(str(x)), axis=1)\n",
        "# text_data = df['combined_text']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('Price', axis=1), df['Price'], test_size=0.2, random_state=0)\n",
        "\n",
        "# Now split the text data\n",
        "X_text_train = X_train.loc[:,text_cols ]\n",
        "X_text_test = X_test.loc[:,text_cols ]"
      ],
      "metadata": {
        "id": "l5I-JLyobGig"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "jTyCu5uhAuS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2422ad03-c302-4bb3-cd6d-662d9122993f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.40)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.35.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the W&B Python Library and log into W&B\n",
        "import wandb\n",
        "\n",
        "wandb.login()\n",
        "\n",
        "#Creamos un proyecto en WandB a través de su interfaz\n",
        "project = \"obligatorio_dl\"\n",
        "entity = \"marian-ai\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p746tMf7_vsP",
        "outputId": "a99a6c39-3605-4dd9-e73f-5b50b10edcdd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmariano-chicatun\u001b[0m (\u001b[33mmarian-ai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "fPVfmc2b8DAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae65e6b6-c758-4991-a1da-eb182efe65d5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import dask.dataframe as dd\n",
        "# from dask.multiprocessing import get\n",
        "\n",
        "# dask_df = dd.from_pandas(X_text_train, npartitions=20)  # Partition dataframe\n",
        "# dask_result = dask_df.map_partitions(lambda df: df.applymap(preprocess_text)).compute(scheduler='multiprocessing')\n"
      ],
      "metadata": {
        "id": "HbmAmYNuBhCE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install fasttext"
      ],
      "metadata": {
        "id": "AvDIVfqERYOV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def basic_cleaning(text):\n",
        "    # Remove HTML tags using BeautifulSoup\n",
        "    if not isinstance(text, str):\n",
        "         return ''\n",
        "\n",
        "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "\n",
        "    # Correct encoding issues\n",
        "    text = text.replace(\"&amp;\", \"&\").replace(\"&lt;\", \"<\").replace(\"&gt;\", \">\")\n",
        "\n",
        "    # Remove special characters or punctuation (customize regex as needed)\n",
        "    text = re.sub(r'[^a-zA-Z0-9.,!?/:;\\\"\\'\\s]', '', text)\n",
        "\n",
        "    # Replace multiple spaces with a single space\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply to a text column in DataFrame\n",
        "X_text_train = X_text_train.applymap(basic_cleaning)\n",
        "X_text_test = X_text_test.applymap(basic_cleaning)\n",
        "\n",
        "\n",
        "X_text_train['combined_text'] = X_text_train.apply(lambda x: ' '.join(x), axis=1)\n",
        "X_text_test['combined_text'] = X_text_test.apply(lambda x: ' '.join(x), axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0ty-q7P8jCh",
        "outputId": "7c86abed-e343-404e-91a5-9c8ef55e82b8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-160adc5ab63a>:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
            "<ipython-input-21-160adc5ab63a>:9: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  text = BeautifulSoup(text, \"html.parser\").get_text()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLAMy9OJ_9-O",
        "outputId": "527b0e1e-85d4-4bab-a520-c36666f42650"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BERT tokenizer and model\n",
        "import tensorflow as tf\n",
        "from transformers import TFBertModel, BertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-multilingual-uncased')\n",
        "seed = 42"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAnHu08U02no",
        "outputId": "350db3e6-f229-4921-fd6e-b75886ace80a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "import tensorflow as tf\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
        "max_length = 128  # Reduce the sequence length if needed\n",
        "\n",
        "def batch_encode(texts, batch_size=256):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        encoded = tokenizer.batch_encode_plus(\n",
        "            batch,\n",
        "            add_special_tokens=True,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='tf'\n",
        "        )\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "\n",
        "    input_ids = tf.concat(input_ids, axis=0)\n",
        "    attention_masks = tf.concat(attention_masks, axis=0)\n",
        "    return input_ids, attention_masks"
      ],
      "metadata": {
        "id": "SVwmWxufuvOH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "train_input_ids, train_attention_masks = batch_encode(X_text_train.combined_text)\n",
        "test_input_ids, test_attention_masks = batch_encode(X_text_test.combined_text)"
      ],
      "metadata": {
        "id": "qxKOkx1avg_R"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(input_ids, attention_masks, labels, batch_size=32):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((\n",
        "        {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_masks\n",
        "        },\n",
        "        labels\n",
        "    ))\n",
        "    dataset = dataset.shuffle(len(labels)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "# Scaling the labels\n",
        "price_scaler = StandardScaler()\n",
        "price_scaler.fit(y_train.to_numpy().reshape(-1, 1))\n",
        "train_labels = price_scaler.transform(y_train.to_numpy().reshape(-1, 1))#.reshape(-1, 1))\n",
        "test_labels = price_scaler.transform(y_test.to_numpy().reshape(-1, 1))#.reshape(-1, 1))\n",
        "\n",
        "# labels = [...]  # Your label data\n",
        "train_dataset = create_dataset(train_input_ids, train_attention_masks, train_labels)\n",
        "test_dataset = create_dataset(test_input_ids, test_attention_masks, test_labels)\n"
      ],
      "metadata": {
        "id": "9n6tA69qvLY6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "def build_model():\n",
        "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='input_ids')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name='attention_mask')\n",
        "\n",
        "    bert_output = bert_model([input_ids, attention_mask])\n",
        "    cls_token_output = bert_output.last_hidden_state[:, 0, :]\n",
        "    output = tf.keras.layers.Dense(1)(cls_token_output)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5, epsilon=1e-8),\n",
        "                  loss=tf.keras.losses.MeanSquaredError(),\n",
        "                  metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "    return model\n",
        "\n",
        "model = build_model()"
      ],
      "metadata": {
        "id": "Bfbx6sVBvplO"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a compiled model 'model'\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=test_dataset,\n",
        "    epochs=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GuKMuwMvMvc",
        "outputId": "80adaf68-a632-442c-cc91-12467ea33fba"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8158/8158 [==============================] - 2503s 302ms/step - loss: 0.3917 - mean_absolute_error: 0.3786 - val_loss: 0.3876 - val_mean_absolute_error: 0.3476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path2 = './obligatorio_DL/private_data_to_predict.csv'\n",
        "data_for_kaggle = pd.read_csv(file_path2)\n",
        "\n",
        "kaggle_test = data_for_kaggle.applymap(basic_cleaning)\n",
        "\n",
        "kaggle_test['combined_text'] = kaggle_test.apply(lambda x: ' '.join(x), axis=1)\n",
        "\n",
        "kaggle_input_ids, kaggle_attention_masks = batch_encode(kaggle_test.combined_text)\n",
        "\n",
        "# Evaluate and predict\n",
        "test_loss, test_mae = model.evaluate(x=[kaggle_input_ids, kaggle_attention_masks], y=test_labels)\n",
        "predictions = model.predict(x=[kaggle_input_ids, kaggle_attention_masks])\n",
        "\n",
        "# Rescale predictions\n",
        "y_pred = price_scaler.inverse_transform(predictions)\n",
        "\n",
        "test_ids = data_for_kaggle['id']\n",
        "test_ids = np.array(test_ids).reshape(-1,1)\n",
        "output = np.stack((test_ids, y_pred), axis=-1)\n",
        "output = output.reshape([-1, 2])\n",
        "df = pd.DataFrame(output)\n",
        "df.columns = ['id','expected']\n",
        "df['expected'] = df['expected'].fillna(0)\n",
        "df.to_csv(\"output_to_submit.csv\", index = False, index_label = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI7PeMzXvxTG",
        "outputId": "d75703c8-1c06-4dc2-b2f5-83b501fb6a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-160adc5ab63a>:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
            "<ipython-input-21-160adc5ab63a>:9: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  text = BeautifulSoup(text, \"html.parser\").get_text()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datos numericos y categoricos"
      ],
      "metadata": {
        "id": "Y8Y8l-JGpd7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Esto esta por probarse con lo de arriba:\n",
        "# Assuming your numeric and categorical preprocessing is already defined\n",
        "X_num_cat_train = preprocessor.fit_transform(X_train)\n",
        "X_num_cat_test = preprocessor.transform(X_test)\n",
        "\n",
        "# Assuming you have already defined your tokenizer and bert_model\n",
        "encoded_corpus_train = tokenizer(text=X_text_train.combined_text.tolist(), ...)\n",
        "encoded_corpus_test = tokenizer(text=X_text_test.combined_text.tolist(), ...)\n",
        "\n",
        "train_inputs = encoded_corpus_train['input_ids']\n",
        "train_masks = encoded_corpus_train['attention_mask']\n",
        "test_inputs = encoded_corpus_test['input_ids']\n",
        "test_masks = encoded_corpus_test['attention_mask']\n",
        "\n",
        "def build_composite_model(bert_model, num_cat_shape):\n",
        "    # Text data input\n",
        "    input_ids = Input(shape=(300,), dtype=tf.int32, name='input_ids')\n",
        "    attention_mask = Input(shape=(300,), dtype=tf.int32, name='attention_mask')\n",
        "\n",
        "    # BERT model for text data\n",
        "    bert_output = bert_model([input_ids, attention_mask])\n",
        "    cls_token_output = bert_output.last_hidden_state[:, 0, :]\n",
        "\n",
        "    # Numeric and Categorical data input\n",
        "    num_cat_input = Input(shape=(num_cat_shape,), name='num_cat_input')\n",
        "\n",
        "    # Combine BERT output with numeric and categorical data\n",
        "    combined = concatenate([cls_token_output, num_cat_input])\n",
        "\n",
        "    # Add dense layers for combined data\n",
        "    hidden_layer = Dense(64, activation='relu')(combined)\n",
        "    output = Dense(1)(hidden_layer)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=[input_ids, attention_mask, num_cat_input], outputs=output)\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "    return model\n",
        "\n",
        "composite_model = build_composite_model(bert_model, X_num_cat_train.shape[1])\n",
        "\n",
        "history = composite_model.fit(\n",
        "    x=[train_inputs, train_masks, X_num_cat_train],\n",
        "    y=train_labels,\n",
        "    validation_data=([test_inputs, test_masks, X_num_cat_test], test_labels),\n",
        "    batch_size=16,\n",
        "    epochs=5\n",
        ")\n",
        "\n",
        "test_loss, test_mae = composite_model.evaluate([test_inputs, test_masks, X_num_cat_test], test_labels)\n",
        "predictions = composite_model.predict([test_inputs, test_masks, X_num_cat_test])\n",
        "\n"
      ],
      "metadata": {
        "id": "houEv5vepfa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_num_cat_kaggle = preprocessor.transform(data_for_kaggle)\n",
        "data_for_kaggle['all_text'] = data_for_kaggle[text_cols].apply(lambda x: ' '.join(str(x)), axis=1)\n",
        "\n",
        "X_text_kaggle_sequences = tokenizer.texts_to_sequences(data_for_kaggle['all_text'])\n",
        "X_text_kaggle_padded = pad_sequences(X_text_kaggle_sequences, maxlen=max_length)\n",
        "\n",
        "kaggle_results = model.predict([X_text_kaggle_padded, X_num_cat_kaggle])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "NS3V6UfdlbSS",
        "outputId": "7e1e099f-f803-48dd-fa5d-edc939e252c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_format\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1391\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m                     \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNaT\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"NaT\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ufunc 'isnat' is only defined for datetime and timedelta.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-037c70ba45f8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# X_num_cat_kaggle = preprocessor.transform(data_for_kaggle)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_for_kaggle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'all_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_for_kaggle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_text_kaggle_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_for_kaggle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'all_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_text_kaggle_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_text_kaggle_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9566\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9567\u001b[0m         )\n\u001b[0;32m-> 9568\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9570\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-037c70ba45f8>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# X_num_cat_kaggle = preprocessor.transform(data_for_kaggle)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_for_kaggle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'all_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_for_kaggle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_text_kaggle_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_for_kaggle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'all_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_text_kaggle_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_text_kaggle_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1592\u001b[0m         \"\"\"\n\u001b[1;32m   1593\u001b[0m         \u001b[0mrepr_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_series_repr_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1594\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrepr_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self, buf, na_rep, float_format, header, index, length, dtype, name, max_rows, min_rows)\u001b[0m\n\u001b[1;32m   1685\u001b[0m             \u001b[0mmax_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m         )\n\u001b[0;32m-> 1687\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# catch contract violations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0mfmt_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhave_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_formatted_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0mfmt_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_formatted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_truncated_vertically\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_get_formatted_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_formatted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         return format_array(\n\u001b[0m\u001b[1;32m    382\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtr_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mformat_array\u001b[0;34m(values, formatter, float_format, na_rep, digits, space, justify, decimal, leading_space, quoting)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     )\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfmt_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m         \u001b[0mfmt_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_make_fixed_width\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmt_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjustify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_format_strings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_float_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mleading_space\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m                 \u001b[0mfmt_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" {_format(v)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_float_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m                 \u001b[0mfmt_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_format\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1390\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m                     \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNaT\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"NaT\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ids = data_for_kaggle['id']\n",
        "test_ids = np.array(test_ids).reshape(-1,1)\n",
        "output = np.stack((test_ids, kaggle_results), axis=-1)\n",
        "output = output.reshape([-1, 2])\n",
        "df = pd.DataFrame(output)\n",
        "df.columns = ['id','expected']\n",
        "df['expected'] = df['expected'].fillna(0)\n",
        "df.to_csv(\"output_to_submit.csv\", index = False, index_label = False)"
      ],
      "metadata": {
        "id": "U9qNjIPmlbSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = word2vec_model.vector_size\n",
        "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in word2vec_model:\n",
        "        embedding_matrix[i] = word2vec_model[word]\n"
      ],
      "metadata": {
        "id": "axIO7wCV9n1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input\n",
        "\n",
        "# Assuming `embedding_matrix` is already defined as per your previous code\n",
        "embedding_layer = Embedding(\n",
        "    input_dim=embedding_matrix.shape[0],\n",
        "    output_dim=embedding_matrix.shape[1],\n",
        "    weights=[embedding_matrix],\n",
        "    trainable=False  # Set to True if you want to fine-tune the embeddings\n",
        ")\n",
        "\n",
        "input_text = Input(shape=(None,), dtype='int32')\n",
        "embedded_text = embedding_layer(input_text)\n",
        "lstm_output, _, _ = LSTM(32, return_sequences=True, return_state=True)(embedded_text)\n",
        "output = Dense(2, activation='softmax')(lstm_output[:, -1, :])\n",
        "\n",
        "model = Model(inputs=input_text, outputs=output)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ArM6HrEe9_qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)])\n",
        "\n",
        "X_num_cat_train = preprocessor.fit_transform(X_train)\n",
        "X_num_cat_test = preprocessor.transform(X_test)\n"
      ],
      "metadata": {
        "id": "6S2VvbH47jbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df,imputer_strategy_numeric,imputer_strategy_categorical,text_tokenizer_num_words,text_max_length):\n",
        "    df_train = df.drop('Price', axis=1)\n",
        "    numerical_cols = df_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "\n",
        "    unique_counts = df_train.drop(numerical_cols, axis=1).nunique()\n",
        "    mean_string_length = df.apply(lambda col: col.dropna().astype(str).apply(len).mean())\n",
        "\n",
        "    unique_value_limit = 20\n",
        "    string_length_limit = 20\n",
        "\n",
        "    categorical_cols = unique_counts[(unique_counts < unique_value_limit) & (mean_string_length < string_length_limit)].index.tolist()\n",
        "    text_cols = unique_counts[(unique_counts >= unique_value_limit) | (mean_string_length >= string_length_limit)].index.tolist()\n",
        "\n",
        "    df['combined_text'] = df[text_cols].apply(lambda x: ' '.join(str(x)), axis=1)\n",
        "    text_data = df['combined_text']\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df.drop('Price', axis=1), df['Price'], test_size=0.2, random_state=0)\n",
        "\n",
        "    X_text_train = X_train['combined_text']\n",
        "    X_text_test = X_test['combined_text']\n",
        "\n",
        "    numeric_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy=imputer_strategy_numeric)),\n",
        "        ('scaler', StandardScaler())])\n",
        "\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy=imputer_strategy_categorical, fill_value='missing')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, numerical_cols),\n",
        "            ('cat', categorical_transformer, categorical_cols)])\n",
        "\n",
        "    X_num_cat_train = preprocessor.fit_transform(X_train)\n",
        "    X_num_cat_test = preprocessor.transform(X_test)\n",
        "\n",
        "    tokenizer = Tokenizer(num_words=text_tokenizer_num_words)\n",
        "    tokenizer.fit_on_texts(X_text_train)\n",
        "\n",
        "    max_length = text_max_length\n",
        "\n",
        "    X_text_train_padded = pad_sequences(tokenizer.texts_to_sequences(X_text_train), maxlen=max_length)\n",
        "    X_text_test_padded = pad_sequences(tokenizer.texts_to_sequences(X_text_test), maxlen=max_length)\n",
        "\n",
        "    return X_num_cat_train, X_text_train_padded, y_train, X_num_cat_test, X_text_test_padded, y_test\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input, Flatten, concatenate, Dropout\n",
        "\n",
        "def build_model(neurons, dropout, optimizer, text_tokenizer_num_words, embedding_output_dim, embedding_matrix):\n",
        "    # Text data input\n",
        "    text_input = Input(shape=(100,), name='text_input')\n",
        "    text_embedding = Embedding(\n",
        "        input_dim=text_tokenizer_num_words,\n",
        "        output_dim=embedding_output_dim,\n",
        "        weights=[embedding_matrix],\n",
        "        trainable=True\n",
        "    )(text_input)\n",
        "    lstm_output, _, _ = LSTM(neurons[0], return_sequences=True, return_state=True)(text_embedding)\n",
        "\n",
        "    num_cat_input = Input(shape=(neurons[1],), name='num_cat_input')\n",
        "\n",
        "    combined_input = concatenate([lstm_output[:, -1, :], num_cat_input])\n",
        "\n",
        "    hidden_layer = Dense(neurons[2], activation='relu')(combined_input)\n",
        "    hidden_dropout = Dropout(dropout)(hidden_layer)\n",
        "\n",
        "    for n in neurons[3:]:\n",
        "        hidden_layer = Dense(n, activation='relu')(hidden_dropout)\n",
        "        hidden_dropout = Dropout(dropout)(hidden_layer)\n",
        "\n",
        "    # Output layer\n",
        "    output_layer = Dense(1)(hidden_dropout)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=[text_input, num_cat_input], outputs=output_layer)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# def build_model(neurons, dropout, optimizer,text_tokenizer_num_words,embedding_output_dim):\n",
        "#     text_input = Input(shape=(100,), name='text_input')\n",
        "#     num_cat_input = Input(shape=(neurons[0],), name='num_cat_input')  # assuming the first layer neuron count for input shape\n",
        "\n",
        "#     text_embedding = Embedding(input_dim=text_tokenizer_num_words, output_dim=embedding_output_dim)(text_input)\n",
        "#     text_flatten = Flatten()(text_embedding)\n",
        "\n",
        "#     combined_input = concatenate([text_flatten, num_cat_input])\n",
        "\n",
        "#     hidden_layer = Dense(neurons[0], activation='relu')(combined_input)\n",
        "#     hidden_dropout = Dropout(dropout)(hidden_layer)\n",
        "\n",
        "#     for n in neurons[1:]:\n",
        "#         hidden_layer = Dense(n, activation='relu')(hidden_dropout)\n",
        "#         hidden_dropout = Dropout(dropout)(hidden_layer)\n",
        "\n",
        "#     output_layer = Dense(1)(hidden_dropout)  # Assuming a regression task\n",
        "\n",
        "#     model = Model(inputs=[text_input, num_cat_input], outputs=output_layer)\n",
        "#     model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "#     return model\n"
      ],
      "metadata": {
        "id": "f5kKi1FuTCTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "sweep_config = {\n",
        "    'name': 'sweep_example',\n",
        "    'method': 'grid',\n",
        "    'metric': {\n",
        "        'name': 'val_loss',\n",
        "        'goal': 'minimize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'dropout': {\n",
        "            'value': 0.1\n",
        "        },\n",
        "        'neurons': {\n",
        "            'values': [[32, 2], [64, 32, 2]]\n",
        "        },\n",
        "        'optimizer': {\n",
        "            'values': ['adam', 'sgd']\n",
        "        },\n",
        "        'imputer_strategy_numeric': {\n",
        "            'values': ['mean', 'median', 'most_frequent', 'constant']\n",
        "        },\n",
        "        'imputer_strategy_categorical': {\n",
        "            'values': ['most_frequent', 'constant']\n",
        "        },\n",
        "        'text_tokenizer_num_words': {\n",
        "            'values': [5000, 10000, 15000]\n",
        "        },\n",
        "        'text_max_length': {\n",
        "            'values': [50, 100, 150]\n",
        "        },\n",
        "        'embedding_output_dim': {\n",
        "            'values': [8, 16, 32]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "pprint.pprint(sweep_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPVPZWmYTcOE",
        "outputId": "26586c4c-4659-4e11-cfeb-0ce940ccd001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'method': 'grid',\n",
            " 'metric': {'goal': 'minimize', 'name': 'val_loss'},\n",
            " 'name': 'sweep_example',\n",
            " 'parameters': {'dropout': {'value': 0.1},\n",
            "                'embedding_output_dim': {'values': [8, 16, 32]},\n",
            "                'imputer_strategy_categorical': {'values': ['most_frequent',\n",
            "                                                            'constant']},\n",
            "                'imputer_strategy_numeric': {'values': ['mean',\n",
            "                                                        'median',\n",
            "                                                        'most_frequent',\n",
            "                                                        'constant']},\n",
            "                'neurons': {'values': [[32, 2], [64, 32, 2]]},\n",
            "                'optimizer': {'values': ['adam', 'sgd']},\n",
            "                'text_max_length': {'values': [50, 100, 150]},\n",
            "                'text_tokenizer_num_words': {'values': [5000, 10000, 15000]}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout, Input, Embedding, Flatten, Dense, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def train():\n",
        "    with wandb.init() as run:\n",
        "        config = run.config\n",
        "        X_num_cat_train, X_text_train_padded, y_train, X_num_cat_test, X_text_test_padded, y_test = preprocess_data(df,config.imputer_strategy_numeric,config.imputer_strategy_categorical,config.text_tokenizer_num_words,config.text_max_length)\n",
        "        model = build_model(config.neurons, config.dropout, config.optimizer,config.embedding_output_dim)\n",
        "        wandb_callback = wandb.keras.WandbCallback()\n",
        "        model.fit([X_text_train_padded, X_num_cat_train], y_train, validation_data=([X_text_test_padded, X_num_cat_test], y_test), epochs=10, batch_size=32, callbacks=[wandb_callback])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1VlYhzTb_hMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=project, entity=entity)\n",
        "wandb.agent(sweep_id, function=train, count=10, project=project, entity=entity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "rPVjLnA0ZzUP",
        "outputId": "069336d2-2e53-436f-a709-940f92ec437e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: dnybgb90\n",
            "Sweep URL: https://wandb.ai/marian-ai/obligatorio_dl/sweeps/dnybgb90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eqlo005i with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_output_dim: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timputer_strategy_categorical: most_frequent\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \timputer_strategy_numeric: mean\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tneurons: [32, 2]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttext_max_length: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ttext_tokenizer_num_words: 5000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmariano-chicatun\u001b[0m (\u001b[33mmarian-ai\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/Colab Notebooks/Datasets/wandb/run-20231030_231007-eqlo005i</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/marian-ai/obligatorio_dl/runs/eqlo005i' target=\"_blank\">celestial-sweep-1</a></strong> to <a href='https://wandb.ai/marian-ai/obligatorio_dl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/marian-ai/obligatorio_dl/sweeps/dnybgb90' target=\"_blank\">https://wandb.ai/marian-ai/obligatorio_dl/sweeps/dnybgb90</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/marian-ai/obligatorio_dl' target=\"_blank\">https://wandb.ai/marian-ai/obligatorio_dl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/marian-ai/obligatorio_dl/sweeps/dnybgb90' target=\"_blank\">https://wandb.ai/marian-ai/obligatorio_dl/sweeps/dnybgb90</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/marian-ai/obligatorio_dl/runs/eqlo005i' target=\"_blank\">https://wandb.ai/marian-ai/obligatorio_dl/runs/eqlo005i</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Etapa previa"
      ],
      "metadata": {
        "id": "GvrjQnZicHzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Defino pipeline de preprocesamiento numerico\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "# Defino pipeline de preprocesamiento categorico\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "# Create a column transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)])\n",
        "\n",
        "# Create a pipeline\n",
        "df_preprocessed = preprocessor.fit_transform(df)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_text_train)\n",
        "max_length = 100\n",
        "X_text_train_padded = pad_sequences(tokenizer.texts_to_sequences(X_text_train), maxlen=max_length)\n",
        "X_text_test_padded = pad_sequences(tokenizer.texts_to_sequences(X_text_test), maxlen=max_length)\n",
        "\n",
        "X_num_cat_train = preprocessor.fit_transform(X_train)\n",
        "X_num_cat_test = preprocessor.transform(X_test)"
      ],
      "metadata": {
        "id": "G56Z9oViXozk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa2c673-fea6-46e7-dba9-b8f285459c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-22-d8fce40df4a2>\", line 21, in <cell line: 21>\n",
            "    tokenizer.fit_on_texts(X_text_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/text.py\", line 293, in fit_on_texts\n",
            "    seq = text_to_word_sequence(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/text.py\", line 80, in text_to_word_sequence\n",
            "    seq = input_text.split(split)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 878, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 396, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, strict, {})\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 431, in _joinrealpath\n",
            "    st = os.lstat(newpath)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[text_cols].dtypes"
      ],
      "metadata": {
        "id": "7zDxLJlWYpfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preproceso la data de texto"
      ],
      "metadata": {
        "id": "EayJNGIvKjYs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uno todos los datos"
      ],
      "metadata": {
        "id": "81NsMtldK3fF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_text_train_padded), len(X_num_cat_train), len(y_train))\n",
        "print(np.any(np.isnan(X_text_train_padded)), np.any(np.isnan(X_num_cat_train)), np.any(np.isnan(y_train)))\n"
      ],
      "metadata": {
        "id": "c_xx3JdaeVOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Assume X_num_cat_train and X_num_cat_test are your numerical and categorical data split into training and test sets\n",
        "# X_num_cat_train, X_num_cat_test, y_train, y_test = train_test_split(df_preprocessed, df['Price'], test_size=0.2, random_state=0)\n",
        "\n",
        "# Separate input layers\n",
        "text_input = Input(shape=(100,), name='text_input')\n",
        "num_cat_input = Input(shape=(X_num_cat_train.shape[1],), name='num_cat_input')\n",
        "\n",
        "# Text data path\n",
        "text_embedding = Embedding(input_dim=5000, output_dim=16)(text_input)\n",
        "text_flatten = Flatten()(text_embedding)\n",
        "\n",
        "# Combine the processing paths\n",
        "combined_input = concatenate([text_flatten, num_cat_input])\n",
        "\n",
        "# Continue with your model\n",
        "hidden_layer = Dense(128, activation='relu')(combined_input)\n",
        "output_layer = Dense(1)(hidden_layer)  # Assuming a regression task\n",
        "\n",
        "model = Model(inputs=[text_input, num_cat_input], outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n"
      ],
      "metadata": {
        "id": "cXNKVTbLK52v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBPTKQutO7_W"
      },
      "source": [
        "### 4.2 Dividir los datos en conjuntos de entrenamiento y prueba"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Wva14b_yK1q-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSemNtYBO7_X"
      },
      "source": [
        "### 4.3 Definir el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z879IPx3O7_X"
      },
      "source": [
        "### 4.4 Entrenar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fU3vaIpO7_X"
      },
      "outputs": [],
      "source": [
        "history = model.fit([X_text_train_padded, X_num_cat_train], y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_UMDxP3O7_X"
      },
      "source": [
        "### 4.5 Evaluar en Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YsNjembO7_X"
      },
      "outputs": [],
      "source": [
        "loss, mae = model.evaluate([X_text_test_padded, X_num_cat_test], y_test, verbose=0)\n",
        "print(f'Test Loss: {loss}')\n",
        "print(f'Test MAE: {mae}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P1lt_pIO7_Y"
      },
      "source": [
        "## 5 Generación de salida para competencia en Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhCrQhrpO7_Y"
      },
      "outputs": [],
      "source": [
        "file_path2 = './obligatorio_DL/private_data_to_predict.csv'\n",
        "data_for_kaggle = pd.read_csv(file_path2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text_cols.remove('combined_text')"
      ],
      "metadata": {
        "id": "WoDhbKOT3yTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_cols)"
      ],
      "metadata": {
        "id": "35hTeHUk4Ryw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_num_cat_kaggle = preprocessor.transform(data_for_kaggle)\n",
        "data_for_kaggle['all_text'] = data_for_kaggle[text_cols].apply(lambda x: ' '.join(str(x)), axis=1)\n",
        "\n",
        "X_text_kaggle_sequences = tokenizer.texts_to_sequences(data_for_kaggle['all_text'])\n",
        "X_text_kaggle_padded = pad_sequences(X_text_kaggle_sequences, maxlen=max_length)\n",
        "\n",
        "kaggle_results = model.predict([X_text_kaggle_padded, X_num_cat_kaggle])\n"
      ],
      "metadata": {
        "id": "TREpyPYF2nZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ids = data_for_kaggle['id']\n",
        "test_ids = np.array(test_ids).reshape(-1,1)\n",
        "output = np.stack((test_ids, kaggle_results), axis=-1)\n",
        "output = output.reshape([-1, 2])\n",
        "df = pd.DataFrame(output)\n",
        "df.columns = ['id','expected']\n",
        "df['expected'] = df['expected'].fillna(0)\n",
        "df.to_csv(\"output_to_submit.csv\", index = False, index_label = False)"
      ],
      "metadata": {
        "id": "LB1JIiCZ2wG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Con WandB"
      ],
      "metadata": {
        "id": "8Lgs9PaF_fNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "gdojPmdWt4OU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "# sweep_config = {\n",
        "# 'name': 'sweep_example',\n",
        "# 'method': 'grid',\n",
        "# 'metric': {\n",
        "#     'name': 'val_loss',\n",
        "#     'goal': 'minimize'\n",
        "# },\n",
        "# 'parameters': {\n",
        "#     'dropout':{'value': 0.1},\n",
        "#     'neurons':{\n",
        "#         'values': [[32,2],[64,32,2]]\n",
        "#         },\n",
        "#     'optimizer': {\n",
        "#         'values': ['adam', 'sgd']\n",
        "#         }\n",
        "# }\n",
        "# }\n",
        "\n",
        "sweep_config = {\n",
        "    'name': 'sweep_example',\n",
        "    'method': 'grid',\n",
        "    'metric': {\n",
        "        'name': 'val_loss',\n",
        "        'goal': 'minimize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'dropout': {'value': 0.1},\n",
        "        'neurons': {'values': [[32, 2], [64, 32, 2]]},\n",
        "        'optimizer': {'values': ['adam', 'sgd']},\n",
        "        'imputer_strategy': {'values': ['mean', 'median', 'most_frequent']},  # Imputer strategies\n",
        "        'scaler': {'values': ['standard', 'minmax']},  # Scaler options: standard scaler or minmax scaler\n",
        "        'text_embedding_dim': {'values': [16, 32]},  # Embedding dimensions for text data\n",
        "    }\n",
        "}\n",
        "\n",
        "pprint.pprint(sweep_config)"
      ],
      "metadata": {
        "id": "nFt2vP6S_y-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import traceback\n",
        "# def run_train():\n",
        "#     try:\n",
        "#         with wandb.init(config=None, project=project, entity=entity):\n",
        "#             # initialize model\n",
        "#             config = wandb.config\n",
        "#             print(config)\n",
        "#             model= get_model(config.neurons, config.optimizer, config.dropout)\n",
        "#             tf.keras.backend.clear_session()\n",
        "#             wandb_callback = wandb.keras.WandbCallback()\n",
        "#             model.fit([X_text_train_padded, X_num_cat_train], y_train,\n",
        "#                       epochs=5, batch_size=128, validation_split=0.2,\n",
        "#                       callbacks=[wandb_callback], max_queue_size=3, workers=2)\n",
        "#     except Exception as e:\n",
        "#         # exit gracefully, so wandb logs the problem\n",
        "#         print(traceback.print_exc(), file=sys.stderr)\n",
        "#         exit(1)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "def run_train():\n",
        "    try:\n",
        "        with wandb.init(config=None, project=project, entity=entity):\n",
        "            # initialize model\n",
        "            config = wandb.config\n",
        "            print(config)\n",
        "\n",
        "            # Configure preprocessing based on sweep config\n",
        "            numeric_transformer = Pipeline(steps=[\n",
        "                ('imputer', SimpleImputer(strategy=config.imputer_strategy)),\n",
        "                ('scaler', StandardScaler() if config.scaler == 'standard' else MinMaxScaler())])\n",
        "\n",
        "            preprocessor = ColumnTransformer(\n",
        "                transformers=[('num', numeric_transformer, numerical_cols)])\n",
        "\n",
        "            X_num_cat_train = preprocessor.fit_transform(X_train)\n",
        "            X_num_cat_test = preprocessor.transform(X_test)\n",
        "\n",
        "            model = get_model(config.neurons, config.optimizer, config.dropout, config.text_embedding_dim)\n",
        "            tf.keras.backend.clear_session()\n",
        "            wandb_callback = wandb.keras.WandbCallback()\n",
        "            model.fit([X_text_train_padded, X_num_cat_train], y_train,\n",
        "                      epochs=5, batch_size=128, validation_split=0.2,\n",
        "                      callbacks=[wandb_callback], max_queue_size=3, workers=2)\n",
        "\n",
        "    except Exception as e:\n",
        "        # exit gracefully, so wandb logs the problem\n",
        "        print(traceback.print_exc(), file=sys.stderr)\n",
        "        exit(1)"
      ],
      "metadata": {
        "id": "w00Vab8P_lMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=project, entity=entity)\n",
        "wandb.agent(sweep_id, function=run_train, count=10, project=project, entity=entity)\n"
      ],
      "metadata": {
        "id": "9TQXlNcS_mnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bert Fine tuning"
      ],
      "metadata": {
        "id": "QrnitVg8t6hm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cambiar a Keras"
      ],
      "metadata": {
        "id": "KImYBr5DuSEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def treat_euro(text):\n",
        "    text = re.sub(r'(euro[^s])|(euros)|(€)', ' euros', text)\n",
        "    return text\n",
        "def treat_m2(text):\n",
        "    text = re.sub(r'(m2)|(m²)', ' m²', text)\n",
        "    return text\n",
        "\n",
        "def filter_ibans(text):\n",
        "    pattern = r'fr\\d{2}[ ]\\d{4}[ ]\\d{4}[ ]\\d{4}[ ]\\d{4}[ ]\\d{2}|fr\\d{20}|fr[ ]\\d{2}[ ]\\d{3}[ ]\\d{3}[ ]\\d{3}[ ]\\d{5}'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "def remove_space_between_numbers(text):\n",
        "    text = re.sub(r'(\\d)\\s+(\\d)', r'\\1\\2', text)\n",
        "    return text\n",
        "def filter_emails(text):\n",
        "    pattern = r'(?:(?!.*?[.]{2})[a-zA-Z0-9](?:[a-zA-Z0-9.+!%-]{1,64}|)|\\\"[a-zA-Z0-9.+!% -]{1,64}\\\")@[a-zA-Z0-9][a-zA-Z0-9.-]+(.[a-z]{2,}|.[0-9]{1,})'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "def filter_ref(text):\n",
        "    pattern = r'(\\(*)(ref|réf)(\\.|[ ])\\d+(\\)*)'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "def filter_websites(text):\n",
        "    pattern = r'(http\\:\\/\\/|https\\:\\/\\/)?([a-z0-9][a-z0-9\\-]*\\.)+[a-z][a-z\\-]*'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "def filter_phone_numbers(text):\n",
        "    pattern = r'(?:(?:\\+|00)33[\\s.-]{0,3}(?:\\(0\\)[\\s.-]{0,3})?|0)[1-9](?:(?:[\\s.-]?\\d{2}){4}|\\d{2}(?:[\\s.-]?\\d{3}){2})|(\\d{2}[ ]\\d{2}[ ]\\d{3}[ ]\\d{3})'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.replace(u'\\xa0', u' ')\n",
        "    text = treat_m2(text)\n",
        "    text = treat_euro(text)\n",
        "    text = filter_phone_numbers(text)\n",
        "    text = filter_emails(text)\n",
        "    text = filter_ibans(text)\n",
        "    text = filter_ref(text)\n",
        "    text = filter_websites(text)\n",
        "    text = remove_space_between_numbers(text)\n",
        "    return text\n",
        "df['cleaned_description'] = df.description.apply(clean_text)\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
        "encoded_corpus = tokenizer(text=df.cleaned_description.tolist(),\n",
        "                            add_special_tokens=True,\n",
        "                            padding='max_length',\n",
        "                            truncation='longest_first',\n",
        "                            max_length=300,\n",
        "                            return_attention_mask=True)\n",
        "input_ids = encoded_corpus['input_ids']\n",
        "attention_mask = encoded_corpus['attention_mask']\n",
        "\n",
        "import numpy as np\n",
        "def filter_long_descriptions(tokenizer, descriptions, max_len):\n",
        "    indices = []\n",
        "    lengths = tokenizer(descriptions, padding=False,\n",
        "                     truncation=False, return_length=True)['length']\n",
        "    for i in range(len(descriptions)):\n",
        "        if lengths[i] <= max_len-2:\n",
        "            indices.append(i)\n",
        "    return indices\n",
        "short_descriptions = filter_long_descriptions(tokenizer,\n",
        "                               df.cleaned_description.tolist(), 300)\n",
        "input_ids = np.array(input_ids)[short_descriptions]\n",
        "attention_mask = np.array(attention_mask)[short_descriptions]\n",
        "labels = df.prix.to_numpy()[short_descriptions]\n",
        "from sklearn.model_selection import train_test_split\n",
        "test_size = 0.1\n",
        "seed = 42\n",
        "train_inputs, test_inputs, train_labels, test_labels = \\\n",
        "            train_test_split(input_ids, labels, test_size=test_size,\n",
        "                             random_state=seed)\n",
        "train_masks, test_masks, _, _ = train_test_split(attention_mask,\n",
        "                                        labels, test_size=test_size,\n",
        "                                        random_state=seed)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "price_scaler = StandardScaler()\n",
        "price_scaler.fit(train_labels.reshape(-1, 1))\n",
        "train_labels = price_scaler.transform(train_labels.reshape(-1, 1))\n",
        "test_labels = price_scaler.transform(test_labels.reshape(-1, 1))\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "batch_size = 32\n",
        "def create_dataloaders(inputs, masks, labels, batch_size):\n",
        "    input_tensor = torch.tensor(inputs)\n",
        "    mask_tensor = torch.tensor(masks)\n",
        "    labels_tensor = torch.tensor(labels)\n",
        "    dataset = TensorDataset(input_tensor, mask_tensor,\n",
        "                            labels_tensor)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size,\n",
        "                            shuffle=True)\n",
        "    return dataloader\n",
        "train_dataloader = create_dataloaders(train_inputs, train_masks,\n",
        "                                      train_labels, batch_size)\n",
        "test_dataloader = create_dataloaders(test_inputs, test_masks,\n",
        "                                     test_labels, batch_size)\n",
        "import torch.nn as nn\n",
        "class BertRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self, drop_rate=0.2, freeze_bert=False):\n",
        "\n",
        "        super(BertRegressor, self).__init__()\n",
        "        D_in, D_out = 768, 1\n",
        "\n",
        "        self.bert = \\\n",
        "                   CamembertModel.from_pretrained('bert-base-multilingual-uncased')\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Dropout(drop_rate),\n",
        "            nn.Linear(D_in, D_out))\n",
        "    def forward(self, input_ids, attention_masks):\n",
        "\n",
        "        outputs = self.bert(input_ids, attention_masks)\n",
        "        class_label_output = outputs[1]\n",
        "        outputs = self.regressor(class_label_output)\n",
        "        return outputs\n",
        "model = BertRegressor(drop_rate=0.2)\n",
        "\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU.\")\n",
        "else:\n",
        "    print(\"No GPU available, using the CPU instead.\")\n",
        "    device = torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "from transformers import AdamW\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=5e-5,\n",
        "                  eps=1e-8)\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 5\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                 num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "loss_function = nn.MSELoss()\n",
        "from torch.nn.utils.clip_grad import clip_grad_norm\n",
        "def train(model, optimizer, scheduler, loss_function, epochs,\n",
        "          train_dataloader, device, clip_value=2):\n",
        "    for epoch in range(epochs):\n",
        "        print(epoch)\n",
        "        print(\"-----\")\n",
        "        best_loss = 1e10\n",
        "        model.train()\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            print(step)\n",
        "            batch_inputs, batch_masks, batch_labels = \\\n",
        "                               tuple(b.to(device) for b in batch)\n",
        "            model.zero_grad()\n",
        "            outputs = model(batch_inputs, batch_masks)\n",
        "            loss = loss_function(outputs.squeeze(),\n",
        "                             batch_labels.squeeze())\n",
        "            loss.backward()\n",
        "            clip_grad_norm(model.parameters(), clip_value)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "    return model\n",
        "model = train(model, optimizer, scheduler, loss_function, epochs,\n",
        "              train_dataloader, device, clip_value=2)\n",
        "\n",
        "def evaluate(model, loss_function, test_dataloader, device):\n",
        "    model.eval()\n",
        "    test_loss, test_r2 = [], []\n",
        "    for batch in test_dataloader:\n",
        "        batch_inputs, batch_masks, batch_labels = \\\n",
        "                                 tuple(b.to(device) for b in batch)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(batch_inputs, batch_masks)\n",
        "        loss = loss_function(outputs, batch_labels)\n",
        "        test_loss.append(loss.item())\n",
        "        r2 = r2_score(outputs, batch_labels)\n",
        "        test_r2.append(r2.item())\n",
        "    return test_loss, test_r2\n",
        "def r2_score(outputs, labels):\n",
        "    labels_mean = torch.mean(labels)\n",
        "    ss_tot = torch.sum((labels - labels_mean) ** 2)\n",
        "    ss_res = torch.sum((labels - outputs) ** 2)\n",
        "    r2 = 1 - ss_res / ss_tot\n",
        "    return r2\n",
        "\n",
        "def predict(model, dataloader, device):\n",
        "    model.eval()\n",
        "    output = []\n",
        "    for batch in dataloader:\n",
        "        batch_inputs, batch_masks, _ = \\\n",
        "                                  tuple(b.to(device) for b in batch)\n",
        "        with torch.no_grad():\n",
        "            output += model(batch_inputs,\n",
        "                            batch_masks).view(1,-1).tolist()[0]\n",
        "    return output\n",
        "\n",
        "val_set = val_data[['id_annonce', 'description', 'prix']]\n",
        "val_set['cleaned_description'] = \\\n",
        "                val_set.description.apply(clean_text)\n",
        "encoded_val_corpus = \\\n",
        "                tokenizer(text=val_set.cleaned_description.tolist(),\n",
        "                          add_special_tokens=True,\n",
        "                          padding='max_length',\n",
        "                          truncation='longest_first',\n",
        "                          max_length=300,\n",
        "                          return_attention_mask=True)\n",
        "val_input_ids = np.array(encoded_val_corpus['input_ids'])\n",
        "val_attention_mask = np.array(encoded_val_corpus['attention_mask'])\n",
        "val_labels = val_set.prix.to_numpy()\n",
        "val_labels = price_scaler.transform(val_labels.reshape(-1, 1))\n",
        "val_dataloader = create_dataloaders(val_input_ids,\n",
        "                         val_attention_mask, val_labels, batch_size)\n",
        "y_pred_scaled = predict(model, val_dataloader, device)\n",
        "\n",
        "y_test = val_set.prix.to_numpy()\n",
        "y_pred = price_scaler.inverse_transform(y_pred_scaled)\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.metrics import r2_score\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mdae = median_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "mdape = ((pd.Series(y_test) - pd.Series(y_pred))\\\n",
        "         / pd.Series(y_test)).abs().median()\n",
        "r_squared = r2_score(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "bhvcXKuXt8Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFBertModel, BertTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Your preprocessing functions and data loading code here...\n",
        "# ...\n",
        "\n",
        "# Load BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-multilingual-uncased')\n",
        "\n",
        "# Assume df is your DataFrame and 'cleaned_description' is the text field\n",
        "encoded_corpus = tokenizer(\n",
        "    text=df.cleaned_description.tolist(),\n",
        "    add_special_tokens=True,\n",
        "    padding='max_length',\n",
        "    truncation='longest_first',\n",
        "    max_length=300,\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='tf'\n",
        ")\n",
        "\n",
        "input_ids = encoded_corpus['input_ids']\n",
        "attention_mask = encoded_corpus['attention_mask']\n",
        "labels = df.prix.to_numpy()\n",
        "\n",
        "# Splitting the data\n",
        "test_size = 0.1\n",
        "seed = 42\n",
        "train_inputs, test_inputs, train_labels, test_labels = \\\n",
        "    train_test_split(input_ids, labels, test_size=test_size, random_state=seed)\n",
        "train_masks, test_masks, _, _ = train_test_split(attention_mask, labels, test_size=test_size, random_state=seed)\n",
        "\n",
        "# Scaling the labels\n",
        "price_scaler = StandardScaler()\n",
        "price_scaler.fit(train_labels.reshape(-1, 1))\n",
        "train_labels = price_scaler.transform(train_labels.reshape(-1, 1))\n",
        "test_labels = price_scaler.transform(test_labels.reshape(-1, 1))\n",
        "\n",
        "# Define the model\n",
        "def build_model():\n",
        "    input_ids = tf.keras.layers.Input(shape=(300,), dtype=tf.int32, name='input_ids')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(300,), dtype=tf.int32, name='attention_mask')\n",
        "\n",
        "    bert_output = bert_model([input_ids, attention_mask])\n",
        "    cls_token_output = bert_output.last_hidden_state[:, 0, :]\n",
        "    output = tf.keras.layers.Dense(1)(cls_token_output)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5, epsilon=1e-8),\n",
        "                  loss=tf.keras.losses.MeanSquaredError(),\n",
        "                  metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x=[train_inputs, train_masks],\n",
        "    y=train_labels,\n",
        "    validation_data=([test_inputs, test_masks], test_labels),\n",
        "    batch_size=32,\n",
        "    epochs=5\n",
        ")\n",
        "\n",
        "# Evaluate and predict\n",
        "test_loss, test_mae = model.evaluate(x=[test_inputs, test_masks], y=test_labels)\n",
        "predictions = model.predict(x=[test_inputs, test_masks])\n",
        "\n",
        "# Rescale predictions\n",
        "y_pred = price_scaler.inverse_transform(predictions)\n",
        "# ...\n",
        "# Your evaluation code here\n",
        "# ...\n"
      ],
      "metadata": {
        "id": "YqI42aNq09fD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}