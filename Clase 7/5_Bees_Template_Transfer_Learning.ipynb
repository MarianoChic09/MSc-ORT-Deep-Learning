{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarianoChic09/MSc-ORT-Deep-Learning/blob/main/Clase%207/5_Bees_Template_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "63fa02cc6f3a2593013a53dcd20bdd9c54533efb",
        "id": "oXG5S-HzQwoO"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gcslBjUDpjKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/Datasets/bees_dataset"
      ],
      "metadata": {
        "id": "C9KlTE3AplvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btT_fGOXQwoR"
      },
      "source": [
        "## 1.1 Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "Yic6kH-SQwoS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout\n",
        "import tensorflow as tf\n",
        "\n",
        "import utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "JVhe3EdPQwoT"
      },
      "source": [
        "## 1.2 Set random seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "d0TwKBKOQwoU"
      },
      "outputs": [],
      "source": [
        "np.random.seed(117)\n",
        "tf.random.set_seed(117)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "acLb2jV1QwoU"
      },
      "source": [
        "## 1.3 Global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "0EsGQ0FmQwoU"
      },
      "outputs": [],
      "source": [
        "img_width = 100\n",
        "img_height = 100\n",
        "img_channels = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "P4hOjJYvQwoV"
      },
      "source": [
        "# 2. Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "5d69ff10797c793abb7c5a05594f8d3463769995",
        "id": "nsyETEZTQwoW"
      },
      "outputs": [],
      "source": [
        "bees, bees_test_for_evaluation = utils.read_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "5d69ff10797c793abb7c5a05594f8d3463769995",
        "id": "jRWzKiHKQwoX",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "bees.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUn4HwxSQwoY"
      },
      "outputs": [],
      "source": [
        "bees_test_for_evaluation.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "1419a5e71da60223177d900fd0e432e46bfa67a0",
        "id": "x26--BG5QwoY"
      },
      "source": [
        "# 3. Análisis exploratorio de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfOPjLlkQwoY"
      },
      "source": [
        "## 3.1 Análisis descriptivo: Distribuciones, Scatterplots, Barplots..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gC-lKAZDQwoZ"
      },
      "outputs": [],
      "source": [
        "utils.value_counts(bees, 'subspecies')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "utils.value_counts(bees, 'location')"
      ],
      "metadata": {
        "id": "7L0__QebyWmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "utils.value_counts(bees, 'zip code')"
      ],
      "metadata": {
        "id": "dTgvYNp_yh_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voy a usar zip code porque se repite Athens, Georgia en location y ya es un numero además."
      ],
      "metadata": {
        "id": "az0hxboTyvOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "utils.value_counts(bees, 'caste')"
      ],
      "metadata": {
        "id": "ZxY5iGNwy074"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tambien voy a dropear caste porque es constante."
      ],
      "metadata": {
        "id": "P35lrF97y_Je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "utils.value_counts(bees, 'pollen_carrying')"
      ],
      "metadata": {
        "id": "9Nb3IWcLy6EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bees.dtypes"
      ],
      "metadata": {
        "id": "f41SDpWVzamN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voy a droppear health porque no esta en el test."
      ],
      "metadata": {
        "id": "h6cgRFDQz3hs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analizo si tengo Nans"
      ],
      "metadata": {
        "id": "FcjmFrGNSFgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bees.isna().sum()"
      ],
      "metadata": {
        "id": "JNMg8cHKSE9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SEOq6ByRdTSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "d750593ed655926232fabd8653ebadde62b19b31",
        "id": "gBvzXNbXQwoZ"
      },
      "source": [
        "## 3.2 Ver imágenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CVFVFzeQwoZ"
      },
      "outputs": [],
      "source": [
        "utils.plot_images(bees, 'location', [0, 18, 24, 38, 45])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "79fb4788f90b3603c8b71472f44647b808bab25e",
        "id": "0_KTALKNQwoa"
      },
      "source": [
        "# 4. Clasificación\n",
        "\n",
        "## 4.1. Data preprocessing\n",
        "### 4.1.1 Particionamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "a167115aa4fcc937097a1c5c8899b909f33fb2d5",
        "id": "xy4LjJijQwoa"
      },
      "outputs": [],
      "source": [
        "train_bees, val_bees, test_bees = utils.split(bees)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XTVEomRFdXZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_bees.isna().sum())\n",
        "print(test_bees.isna().sum())"
      ],
      "metadata": {
        "id": "hXt5xJlmbwJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_zip_code = set(train_bees['zip code'].unique())\n",
        "val_set_zip_code = set(val_bees['zip code'].unique())\n",
        "test_set_zip_code = set(test_bees['zip code'].unique())\n",
        "\n",
        "print(train_set_zip_code == val_set_zip_code)\n",
        "print(train_set_zip_code == test_set_zip_code)"
      ],
      "metadata": {
        "id": "vGxpK_GOarnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "e9650143e38ccda561450d08d241cb7ce51c89e8",
        "id": "ulGPGZ9DQwoa"
      },
      "source": [
        "\n",
        "### 4.1.2 Carga de imágenes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/Datasets/bees_dataset\")\n"
      ],
      "metadata": {
        "id": "bNzZiNaA9zCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "id": "ssoy8VWp96TY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir())\n",
        "os.chdir(\"./data/imgs\")\n",
        "print(os.listdir())\n",
        "os.chdir(\"../../\")"
      ],
      "metadata": {
        "id": "R_b3Nn6R-IJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# os.chdir(\"../../\")\n",
        "# print(os.listdir())\n"
      ],
      "metadata": {
        "id": "xOUXO89g_A2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "dcda4508b7424518d4c11a0e4b7ad2a05f803601",
        "id": "Anm7kk9dQwoa"
      },
      "outputs": [],
      "source": [
        "train_X, val_X, test_X, train_y, val_y, test_y = utils.load_images_and_target(train_bees,\n",
        "                                                                              val_bees,\n",
        "                                                                              test_bees,\n",
        "                                                                              'subspecies',\n",
        "                                                                              img_width,\n",
        "                                                                              img_height,\n",
        "                                                                              img_channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBpdE2oJQwob"
      },
      "outputs": [],
      "source": [
        "optimizer = 'sgd'\n",
        "loss = 'categorical_crossentropy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "053d12032f6d113094617826f5f78bba8555c115",
        "id": "ZreSxY3jQwob"
      },
      "outputs": [],
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Flatten(input_shape =(img_height, img_width, img_channels)))\n",
        "model1.add(Dense(train_y.columns.size, activation = 'softmax'))\n",
        "model1.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iyYrMeXQwob"
      },
      "source": [
        "## 4.3 Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y99Q6AkQwob"
      },
      "source": [
        "### 4.2.2 Parámetros de transformación de imágenes (data augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kANj43YQwob"
      },
      "outputs": [],
      "source": [
        "rotation_range = 15      # rotación aleatoria en grados entre 0 a rotation_range\n",
        "zoom_range = 0.1         # zoom aleatorio\n",
        "width_shift_range = 0.1  # desplazamiento horizontal aleatorio (fracción del total)\n",
        "height_shift_range = 0.1 # desplazamiento vertical aleatorio (fracción del total)\n",
        "horizontal_flip = True   # transposición horizontal\n",
        "vertical_flip = True     # transposición horizontal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "053d12032f6d113094617826f5f78bba8555c115",
        "id": "ntCHkSQJQwoc"
      },
      "outputs": [],
      "source": [
        "batch_size = 10\n",
        "epochs = 5\n",
        "steps_per_epoch = 10\n",
        "patience = 10\n",
        "class_weights = utils.class_weights(bees, 'subspecies')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPhnNDYDQwoc"
      },
      "outputs": [],
      "source": [
        "class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "053d12032f6d113094617826f5f78bba8555c115",
        "id": "rlLcUoNBQwoc"
      },
      "outputs": [],
      "source": [
        "training1, model1 = utils.train(model1,\n",
        "                train_X,\n",
        "                train_y,\n",
        "                batch_size = batch_size,\n",
        "                epochs = epochs,\n",
        "                validation_data_X = val_X,\n",
        "                validation_data_y = val_y,\n",
        "                steps_per_epoch = steps_per_epoch,\n",
        "                rotation_range = rotation_range,\n",
        "                zoom_range = zoom_range,\n",
        "                width_shift_range = width_shift_range,\n",
        "                height_shift_range = height_shift_range,\n",
        "                horizontal_flip = horizontal_flip,\n",
        "                vertical_flip = vertical_flip,\n",
        "                patience = patience,\n",
        "                class_weights = class_weights\n",
        "                               )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8fCcgUxIbvd3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ac639c24adf884c806ce1ab985fe7db7e9aab26a",
        "id": "racq5zNsQwoc"
      },
      "source": [
        "## 4.3 Evaluación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "b096e119c62a41dc227ad9f12131ca0c28dbed8b",
        "id": "bwSDz8nSQwoc"
      },
      "outputs": [],
      "source": [
        "utils.eval_model(training1, model1, test_X, test_y, 'subspecies')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4hBsoQoQwoc"
      },
      "source": [
        "## 4.4 Evaluación y generación de archivo para competencia Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVC9MKbFQwod"
      },
      "outputs": [],
      "source": [
        " df_subspecies = utils.load_test_and_generate_prediction_file(model1, img_width, img_height, img_channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHv0yB4EQwod"
      },
      "outputs": [],
      "source": [
        "df_subspecies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl3JS2paTZvN"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1T8uyxXUFAZ"
      },
      "source": [
        "## Qué es Transfer Learning?\n",
        "\n",
        "Transfer learning o aprendizaje por transferencia es un problema de investigación en el aprendizaje automático que se centra en almacenar el conocimiento adquirido mientras se resuelve un problema y se aplica a un problema diferente pero relacionado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2fFr2fDT09U"
      },
      "source": [
        "[Keras Models](https://keras.io/api/applications/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36l4mc_ASjQi"
      },
      "outputs": [],
      "source": [
        "# example of loading the vgg16 model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "# load model\n",
        "\n",
        "model = VGG16(input_shape=(img_height, img_width, img_channels), include_top=False)\n",
        "# model = VGG16(input_shape=(224, 224, 3), include_top=True)\n",
        "\n",
        "# summarize the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers[:-3]:\n",
        "  layer.trainable = False\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "-tGgeHiXs9ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqjmTPimQwod"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "flat1 = Flatten()(model.layers[-1].output)\n",
        "class1 = Dense(1024, activation='relu')(flat1)\n",
        "output = Dense(7, activation='softmax')(class1)\n",
        "\n",
        "# define new model\n",
        "model = Model(inputs=model.inputs, outputs=output)\n",
        "\n",
        "optimizer = 'sgd'\n",
        "loss = 'categorical_crossentropy'\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiyHbHo9ZCeK"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8JmKOQXdxAD"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0o5He4JdxAK"
      },
      "source": [
        "Parámetros de transformación de imágenes (data augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALScY_bsdxAK"
      },
      "outputs": [],
      "source": [
        "rotation_range = 15      # rotación aleatoria en grados entre 0 a rotation_range\n",
        "zoom_range = 0.1         # zoom aleatorio\n",
        "width_shift_range = 0.1  # desplazamiento horizontal aleatorio (fracción del total)\n",
        "height_shift_range = 0.1 # desplazamiento vertical aleatorio (fracción del total)\n",
        "horizontal_flip = True   # transposición horizontal\n",
        "vertical_flip = True     # transposición horizontal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "def computing_class_weights(df, class_name):\n",
        "    class_labels = {name: index for index, name in enumerate(np.unique(df[class_name]))}\n",
        "    y_integers = np.array([class_labels[name] for name in df[class_name]])\n",
        "    weights = compute_sample_weight(class_weight='balanced', y=y_integers)\n",
        "\n",
        "    weight_dict = {}\n",
        "    for class_index in class_labels.values():\n",
        "        weight_dict[class_index] = weights[y_integers == class_index].mean()\n",
        "\n",
        "    return weight_dict\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def weighted_accuracy(weight_dict):\n",
        "    class_weights = tf.constant([weight_dict[i] for i in range(len(weight_dict))])\n",
        "\n",
        "    def calc_weighted_accuracy(y_true, y_pred):\n",
        "        y_true_labels = K.argmax(y_true, axis=1)\n",
        "        y_pred_labels = K.argmax(y_pred, axis=1)\n",
        "\n",
        "        correct_predictions = K.cast(K.equal(y_true_labels, y_pred_labels), dtype='float32')\n",
        "        weights = K.gather(class_weights, y_true_labels)\n",
        "        weighted_correct_predictions = correct_predictions * weights\n",
        "\n",
        "        accuracy = K.sum(weighted_correct_predictions) / K.sum(weights)\n",
        "        return accuracy\n",
        "\n",
        "    return calc_weighted_accuracy\n"
      ],
      "metadata": {
        "id": "B5qvREQ85T_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "053d12032f6d113094617826f5f78bba8555c115",
        "id": "Ln2utLxYdxAK"
      },
      "outputs": [],
      "source": [
        "batch_size = 10\n",
        "epochs = 500\n",
        "steps_per_epoch = 10\n",
        "patience = 100\n",
        "\n",
        "class_weights = computing_class_weights(bees, 'subspecies')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3zHgoDkdxAK"
      },
      "outputs": [],
      "source": [
        "class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "053d12032f6d113094617826f5f78bba8555c115",
        "id": "kKxbG7cEdxAK"
      },
      "outputs": [],
      "source": [
        "training_vgg16, model = utils.train(model,\n",
        "                train_X,\n",
        "                train_y,\n",
        "                batch_size = batch_size,\n",
        "                epochs = epochs,\n",
        "                validation_data_X = val_X,\n",
        "                validation_data_y = val_y,\n",
        "                steps_per_epoch = steps_per_epoch,\n",
        "                rotation_range = rotation_range,\n",
        "                zoom_range = zoom_range,\n",
        "                width_shift_range = width_shift_range,\n",
        "                height_shift_range = height_shift_range,\n",
        "                horizontal_flip = horizontal_flip,\n",
        "                vertical_flip = vertical_flip,\n",
        "                patience = patience,\n",
        "                class_weights = class_weights\n",
        "                               )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params = ((3*3*512)*1024+1024)+(1024*7+7)\n",
        "trainable_params"
      ],
      "metadata": {
        "id": "k9I3X1RFsTIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ac639c24adf884c806ce1ab985fe7db7e9aab26a",
        "id": "RzVAN-zMeMRA"
      },
      "source": [
        "## Evaluación del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "b096e119c62a41dc227ad9f12131ca0c28dbed8b",
        "id": "C6yla0_DeMRH"
      },
      "outputs": [],
      "source": [
        "utils.eval_model(training_vgg16, model, test_X, test_y, 'subspecies')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imbalanced Learning\n"
      ],
      "metadata": {
        "id": "0srZY51uBFwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Archivo para Kaggle"
      ],
      "metadata": {
        "id": "83y0x2WEL1gG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_subspecies = utils.load_test_and_generate_prediction_file(model1, img_width, img_height, img_channels)\n",
        "df_subspecies"
      ],
      "metadata": {
        "id": "FJv4DQrZL4Cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minority_images\n"
      ],
      "metadata": {
        "id": "4w9UkeXR3kO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w21AErqZLbD"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create a new ImageDataGenerator with the desired augmentations\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Assuming minority_images is a numpy array of images from the minority class\n",
        "augmented_images = []\n",
        "num_augmentations_per_image = 10  # You can adjust this value based on how many augmented images you want per original image\n",
        "\n",
        "for img in minority_images:\n",
        "    img = img.reshape((1,) + img.shape)  # Reshape the image\n",
        "    i = 0\n",
        "    for batch in datagen.flow(img, batch_size=1):\n",
        "        augmented_images.append(batch[0])\n",
        "        i += 1\n",
        "        if i >= num_augmentations_per_image:\n",
        "            break  # Avoid generator to loop indefinitely\n",
        "\n",
        "# Now, `augmented_images` will contain the augmented images, and you can add these images to your training dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG 19"
      ],
      "metadata": {
        "id": "LpDV2Mmtd20j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of loading the vgg16 model\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "# load model\n",
        "\n",
        "model = VGG19(input_shape=(img_height, img_width, img_channels), include_top=False)\n",
        "# model = VGG16(input_shape=(224, 224, 3), include_top=True)\n",
        "\n",
        "# summarize the model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "WisBt30Pd4Op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers[:-3]:\n",
        "  layer.trainable = False\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "1arAcqg9eWsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tBUVAPueWsl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "flat1 = Flatten()(model.layers[-1].output)\n",
        "class1 = Dense(1024, activation='relu')(flat1)\n",
        "output = Dense(7, activation='softmax')(class1)\n",
        "\n",
        "# define new model\n",
        "model = Model(inputs=model.inputs, outputs=output)\n",
        "\n",
        "optimizer = 'sgd'\n",
        "loss = 'categorical_crossentropy'\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKLzF33NeWsm"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-JWUioueWsm"
      },
      "outputs": [],
      "source": [
        "rotation_range = 15      # rotación aleatoria en grados entre 0 a rotation_range\n",
        "zoom_range = 0.1         # zoom aleatorio\n",
        "width_shift_range = 0.1  # desplazamiento horizontal aleatorio (fracción del total)\n",
        "height_shift_range = 0.1 # desplazamiento vertical aleatorio (fracción del total)\n",
        "horizontal_flip = True   # transposición horizontal\n",
        "vertical_flip = True     # transposición horizontal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "def computing_class_weights(df, class_name):\n",
        "    class_labels = {name: index for index, name in enumerate(np.unique(df[class_name]))}\n",
        "    y_integers = np.array([class_labels[name] for name in df[class_name]])\n",
        "    weights = compute_sample_weight(class_weight='balanced', y=y_integers)\n",
        "\n",
        "    weight_dict = {}\n",
        "    for class_index in class_labels.values():\n",
        "        weight_dict[class_index] = weights[y_integers == class_index].mean()\n",
        "\n",
        "    return weight_dict"
      ],
      "metadata": {
        "id": "29MmcsGgeWsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "053d12032f6d113094617826f5f78bba8555c115",
        "id": "gB9FqMyieWsn"
      },
      "outputs": [],
      "source": [
        "batch_size = 10\n",
        "epochs = 500\n",
        "steps_per_epoch = 10\n",
        "patience = 100\n",
        "\n",
        "class_weights = computing_class_weights(bees, 'subspecies')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pW28yqNeWsn"
      },
      "outputs": [],
      "source": [
        "class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "053d12032f6d113094617826f5f78bba8555c115",
        "id": "HBL6qFyaeWso"
      },
      "outputs": [],
      "source": [
        "training_vgg19, model = utils.train(model,\n",
        "                train_X,\n",
        "                train_y,\n",
        "                batch_size = batch_size,\n",
        "                epochs = epochs,\n",
        "                validation_data_X = val_X,\n",
        "                validation_data_y = val_y,\n",
        "                steps_per_epoch = steps_per_epoch,\n",
        "                rotation_range = rotation_range,\n",
        "                zoom_range = zoom_range,\n",
        "                width_shift_range = width_shift_range,\n",
        "                height_shift_range = height_shift_range,\n",
        "                horizontal_flip = horizontal_flip,\n",
        "                vertical_flip = vertical_flip,\n",
        "                patience = patience,\n",
        "                class_weights = class_weights\n",
        "                               )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "b096e119c62a41dc227ad9f12131ca0c28dbed8b",
        "id": "8MKdSDxkeWso"
      },
      "outputs": [],
      "source": [
        "utils.eval_model(training_vgg19, model, test_X, test_y, 'subspecies')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_subspecies = utils.load_test_and_generate_prediction_file(model1, img_width, img_height, img_channels)\n",
        "df_subspecies"
      ],
      "metadata": {
        "id": "KdwZXElNeWso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet 50"
      ],
      "metadata": {
        "id": "hx9zMXEjd41y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "def computing_class_weights(df, class_name):\n",
        "    class_labels = {name: index for index, name in enumerate(np.unique(df[class_name]))}\n",
        "    y_integers = np.array([class_labels[name] for name in df[class_name]])\n",
        "    weights = compute_sample_weight(class_weight='balanced', y=y_integers)\n",
        "\n",
        "    weight_dict = {}\n",
        "    for class_index in class_labels.values():\n",
        "        weight_dict[class_index] = weights[y_integers == class_index].mean()\n",
        "\n",
        "    return weight_dict\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def weighted_accuracy(weight_dict):\n",
        "    class_weights = tf.constant([weight_dict[i] for i in range(len(weight_dict))])\n",
        "\n",
        "    def calc_weighted_accuracy(y_true, y_pred):\n",
        "        y_true_labels = K.argmax(y_true, axis=1)\n",
        "        y_pred_labels = K.argmax(y_pred, axis=1)\n",
        "\n",
        "        correct_predictions = K.cast(K.equal(y_true_labels, y_pred_labels), dtype='float32')\n",
        "        weights = K.gather(class_weights, y_true_labels)\n",
        "        weighted_correct_predictions = correct_predictions * weights\n",
        "\n",
        "        accuracy = K.sum(weighted_correct_predictions) / K.sum(weights)\n",
        "        return accuracy\n",
        "\n",
        "    return calc_weighted_accuracy"
      ],
      "metadata": {
        "id": "GfVzyrMdsrl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.ResNet50V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"
      ],
      "metadata": {
        "id": "FJTfzWS8d7W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of loading the vgg16 model\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
        "# load model\n",
        "\n",
        "model_ResNet152V2 = ResNet152V2(input_shape=(img_height, img_width, img_channels), include_top=False)\n",
        "# model = VGG16(input_shape=(224, 224, 3), include_top=True)\n",
        "\n",
        "# summarize the model\n",
        "model_ResNet152V2.summary()"
      ],
      "metadata": {
        "id": "RR_YUOobf3fP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_ResNet152V2.layers[:-6]:\n",
        "  layer.trainable = False\n",
        "model_ResNet152V2.summary()"
      ],
      "metadata": {
        "id": "oV-MN1kGf3fQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGTRkhaEf3fQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Model, models, layers, optimizers\n",
        "\n",
        "# flat1 = Flatten()(model.layers[-1].output)\n",
        "# class1 = Dense(1024, activation='relu')(flat1)\n",
        "# output = Dense(7, activation='softmax')(class1)\n",
        "\n",
        "# # define new model\n",
        "# model = Model(inputs=model.inputs, outputs=output)\n",
        "# model.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(1024, activation='relu'),\n",
        "    layers.Dropout(0.5),  # Optional: for regularization\n",
        "    layers.Dense(7, activation='softmax')  # Adjust for the number of classes in your dataset\n",
        "])\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=1e-4)\n",
        "loss = 'categorical_crossentropy'\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gztqnppdf3fQ"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeCiJgNlf3fR"
      },
      "outputs": [],
      "source": [
        "rotation_range = 180      # rotación aleatoria en grados entre 0 a rotation_range\n",
        "zoom_range = 0.1         # zoom aleatorio\n",
        "width_shift_range = 0.1  # desplazamiento horizontal aleatorio (fracción del total)\n",
        "height_shift_range = 0.1 # desplazamiento vertical aleatorio (fracción del total)\n",
        "horizontal_flip = True   # transposición horizontal\n",
        "vertical_flip = True     # transposición horizontal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "def computing_class_weights(df, class_name):\n",
        "    class_labels = {name: index for index, name in enumerate(np.unique(df[class_name]))}\n",
        "    y_integers = np.array([class_labels[name] for name in df[class_name]])\n",
        "    weights = compute_sample_weight(class_weight='balanced', y=y_integers)\n",
        "\n",
        "    weight_dict = {}\n",
        "    for class_index in class_labels.values():\n",
        "        weight_dict[class_index] = weights[y_integers == class_index].mean()\n",
        "\n",
        "    return weight_dict"
      ],
      "metadata": {
        "id": "xeyzj6yMf3fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "053d12032f6d113094617826f5f78bba8555c115",
        "id": "hG3UZFGVf3fR"
      },
      "outputs": [],
      "source": [
        "batch_size = 10\n",
        "epochs = 1500\n",
        "steps_per_epoch = 10\n",
        "patience = 100\n",
        "\n",
        "class_weights = computing_class_weights(bees, 'subspecies')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmldulJgf3fR"
      },
      "outputs": [],
      "source": [
        "class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "053d12032f6d113094617826f5f78bba8555c115",
        "id": "yLbSHqY4f3fR"
      },
      "outputs": [],
      "source": [
        "training_resnet152V2, model = utils.train(model,\n",
        "                train_X,\n",
        "                train_y,\n",
        "                batch_size = batch_size,\n",
        "                epochs = epochs,\n",
        "                validation_data_X = val_X,\n",
        "                validation_data_y = val_y,\n",
        "                steps_per_epoch = steps_per_epoch,\n",
        "                rotation_range = rotation_range,\n",
        "                zoom_range = zoom_range,\n",
        "                width_shift_range = width_shift_range,\n",
        "                height_shift_range = height_shift_range,\n",
        "                horizontal_flip = horizontal_flip,\n",
        "                vertical_flip = vertical_flip,\n",
        "                patience = patience,\n",
        "                class_weights = class_weights\n",
        "                               )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "b096e119c62a41dc227ad9f12131ca0c28dbed8b",
        "id": "pX79pQQtf3fR"
      },
      "outputs": [],
      "source": [
        "utils.eval_model(training_resnet152V2, model, test_X, test_y, 'subspecies')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_subspecies = utils.load_test_and_generate_prediction_file(model, img_width, img_height, img_channels)\n",
        "df_subspecies"
      ],
      "metadata": {
        "id": "gTU1KchGj5Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combinando con la metadata\n",
        "Combinando la información de las imágenes con la metadata disponible"
      ],
      "metadata": {
        "id": "1wswCLeStrCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_bees, val_bees, test_bees = utils.split(bees)"
      ],
      "metadata": {
        "id": "iJsHlPd4hVrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "encoder.fit(train_bees[['zip code']])\n",
        "\n",
        "def preprocess_metadata(df, encoder):\n",
        "\n",
        "    zip_encoded = encoder.transform(df[['zip code']])\n",
        "\n",
        "\n",
        "    zip_df = pd.DataFrame(zip_encoded, columns=encoder.get_feature_names_out(['zip code']))\n",
        "\n",
        "    zip_df = zip_df.reset_index(drop=True)\n",
        "    pollen_df = df['pollen_carrying'].reset_index(drop=True)\n",
        "\n",
        "    pollen_df = pollen_df.astype(int)\n",
        "\n",
        "    meta_df = pd.concat([zip_df, pollen_df], axis=1)\n",
        "\n",
        "    return meta_df\n",
        "\n",
        "def load_images_and_target_with_metadata(train_bees, val_bees, test_bees, y_field_name, img_width, img_height, img_channels, encoder):\n",
        "    \"\"\"\n",
        "    Load images for features, drop other columns\n",
        "    One hot encode for label, drop other columns\n",
        "    @return: train images, validation images, test images, train labels, validation labels, test labels\n",
        "    \"\"\"\n",
        "    # Bees already splitted to train, validation and test\n",
        "    # Load and transform images to have equal width/height/channels.\n",
        "    # Use np.stack to get NumPy array for CNN input\n",
        "    img_folder='./data/imgs/'\n",
        "\n",
        "\n",
        "    # Train data\n",
        "    train_X = np.stack(train_bees['file'].apply(lambda x: utils.read_img(x, img_folder, img_width, img_height, img_channels)))\n",
        "    train_y = pd.DataFrame(utils.onehot_encoding(train_bees, y_field_name))\n",
        "    # train_y  = pd.get_dummies(train_bees[y_field_name], drop_first=False)\n",
        "\n",
        "    # Validation during training data to calc val_loss metric\n",
        "    val_X = np.stack(val_bees['file'].apply(lambda x: utils.read_img(x, img_folder, img_width, img_height, img_channels)))\n",
        "    val_y = pd.DataFrame(utils.onehot_encoding(val_bees, y_field_name))\n",
        "    # val_y = pd.get_dummies(val_bees[y_field_name], drop_first=False)\n",
        "\n",
        "    # Test data\n",
        "    test_X = np.stack(test_bees['file'].apply(lambda x: utils.read_img(x, img_folder, img_width, img_height, img_channels)))\n",
        "    test_y = pd.DataFrame(utils.onehot_encoding(test_bees, y_field_name))\n",
        "    # test_y = pd.get_dummies(test_bees[y_field_name], drop_first=False)\n",
        "\n",
        "    # encoder = OneHotEncoder(sparse_output=False)\n",
        "    # encoder.fit(train_bees[['zip code']])\n",
        "\n",
        "\n",
        "    train_meta = preprocess_metadata(train_bees,encoder)\n",
        "    val_meta = preprocess_metadata(val_bees,encoder)\n",
        "    test_meta = preprocess_metadata(test_bees,encoder)\n",
        "\n",
        "    return (train_X, val_X, test_X, train_y, val_y, test_y, train_meta, val_meta, test_meta)\n"
      ],
      "metadata": {
        "id": "uky41Z07Pjt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, val_X, test_X, train_y, val_y, test_y, train_meta, val_meta, test_meta = load_images_and_target_with_metadata(train_bees,\n",
        "                                                                              val_bees,\n",
        "                                                                              test_bees,\n",
        "                                                                              'subspecies',\n",
        "                                                                              img_width,\n",
        "                                                                              img_height,\n",
        "                                                                              img_channels)"
      ],
      "metadata": {
        "id": "NFTXdWrxP1Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_bees))\n",
        "print(len(val_bees))\n",
        "print(len(test_bees))\n",
        "print(\"-------------------------------------\")\n",
        "print(f\"Size of metadata {train_meta.shape[0]}. Size of images: {train_X.shape[0]}\")\n",
        "print(f\"Size of metadata {val_meta.shape[0]}. Size of images: {val_X.shape[0]}\")\n",
        "print(f\"Size of metadata {test_meta.shape[0]}. Size of images: {test_X.shape[0]}\")\n",
        "\n",
        "print(test_meta.shape)"
      ],
      "metadata": {
        "id": "oSfhahLbeATF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LFch_mYvl8Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "\n",
        "def create_combined_model(image_model, metadata_model,num_classes):\n",
        "    combined_input = concatenate([image_model.output, metadata_model.output])\n",
        "\n",
        "    # You can add more dense layers here if needed\n",
        "    z = Dense(num_classes, activation='softmax')(combined_input)  # Assuming num_classes is pre-defined\n",
        "\n",
        "    combined_model = Model(inputs=[image_model.input, metadata_model.input], outputs=z)\n",
        "\n",
        "    return combined_model\n",
        "\n",
        "def combined_gen(image_gen, meta_data):\n",
        "    for (x, y) in image_gen:\n",
        "        yield [x, meta_data], y\n",
        "\n",
        "def combined_generator(img_data, meta_data, labels, batch_size):\n",
        "    num_samples = img_data.shape[0]\n",
        "    while True:\n",
        "        for i in range(0, num_samples, batch_size):\n",
        "            end = min(i + batch_size, num_samples)\n",
        "            img_batch = img_data[i:end]\n",
        "            meta_batch = meta_data[i:end]\n",
        "            label_batch = labels[i:end]\n",
        "            yield [img_batch, meta_batch], label_batch\n",
        "\n",
        "def train_with_metadata(model,\n",
        "                train_X,\n",
        "                train_y,\n",
        "                train_meta,\n",
        "                val_meta,\n",
        "                batch_size,\n",
        "                epochs,\n",
        "                validation_data_X,\n",
        "                validation_data_y,\n",
        "                steps_per_epoch,\n",
        "                rotation_range,  # ... other augmentation parameters\n",
        "                patience,\n",
        "                class_weights=None):\n",
        "\n",
        "    datagen = ImageDataGenerator(featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "                                samplewise_center=False,  # set each sample mean to 0\n",
        "                                featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "                                samplewise_std_normalization=False,  # divide each input by its std\n",
        "                                zca_whitening=False,  # apply ZCA whitening\n",
        "                                rotation_range=rotation_range,  # randomly rotate images in the range (degrees, 0 to rotation_range)\n",
        "                                zoom_range = zoom_range, # Randomly zoom image\n",
        "                                width_shift_range=width_shift_range,  # randomly shift images horizontally (fraction of total width)\n",
        "                                height_shift_range=height_shift_range,  # randomly shift images vertically (fraction of total height)\n",
        "                                horizontal_flip=horizontal_flip,  # randomly flip images\n",
        "                                vertical_flip=vertical_flip)\n",
        "\n",
        "    train_gen = datagen.flow(train_X, train_y, batch_size=batch_size)\n",
        "    # combined_train_gen = combined_gen(train_gen, train_meta)\n",
        "    combined_train_gen = combined_generator(train_X, train_meta, train_y, batch_size=32)\n",
        "\n",
        "\n",
        "    # Train\n",
        "    ## Callbacks\n",
        "    earlystopper = EarlyStopping(monitor='loss', patience=patience, verbose=1, restore_best_weights=True)\n",
        "\n",
        "    training = model.fit(\n",
        "        combined_train_gen,\n",
        "        validation_data=([validation_data_X, val_meta], validation_data_y),\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=epochs,\n",
        "        callbacks=[earlystopper],\n",
        "        class_weight=class_weights\n",
        "        # ... other parameters\n",
        "    )\n",
        "    return training, model\n"
      ],
      "metadata": {
        "id": "vPG6X8_NiEWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of loading the vgg16 model\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "# load model\n",
        "\n",
        "model_ResNet50V2 = ResNet50V2(input_shape=(img_height, img_width, img_channels), include_top=False)\n",
        "# model = VGG16(input_shape=(224, 224, 3), include_top=True)\n",
        "\n",
        "# summarize the model\n",
        "# model_ResNet152V2.summary()"
      ],
      "metadata": {
        "id": "8SpTwWS9LBvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_ResNet50V2.layers[:-3]:\n",
        "  layer.trainable = False\n",
        "# model_ResNet152V2.summary()"
      ],
      "metadata": {
        "id": "qobjO6bGLBvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model, models, layers, optimizers\n",
        "\n",
        "# flat1 = Flatten()(model.layers[-1].output)\n",
        "# class1 = Dense(1024, activation='relu')(flat1)\n",
        "# output = Dense(7, activation='softmax')(class1)\n",
        "\n",
        "# # define new model\n",
        "# model = Model(inputs=model.inputs, outputs=output)\n",
        "# model.trainable = False\n",
        "\n",
        "image_model = models.Sequential([\n",
        "    model_ResNet50V2,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(1024, activation='relu'),\n",
        "    layers.Dropout(0.5),  # Optional: for regularization\n",
        "    # layers.Dense(7, activation='softmax')  # Adjust for the number of classes in your dataset\n",
        "])\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=1e-5)\n",
        "loss = 'categorical_crossentropy'\n",
        "\n",
        "# compile the model\n",
        "image_model.compile(optimizer=optimizer,\n",
        "              loss=loss,\n",
        "              metrics=['accuracy'])\n",
        "image_model.summary()"
      ],
      "metadata": {
        "id": "dQWKSu5Ejgwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.regularizers import l2 # Agrego regularización porque al agregar la metadata tomaba demasiado en cuenta estos valores.\n",
        "\n",
        "# Define the metadata model\n",
        "metadata_input = Input(shape=(8,))\n",
        "metadata_layer = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(metadata_input)\n",
        "metadata_layer = Dropout(0.5)(metadata_layer)\n",
        "metadata_model = Model(inputs=metadata_input, outputs=metadata_layer)\n",
        "\n",
        "combined_model = create_combined_model(image_model, metadata_model,num_classes=7)\n",
        "combined_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "metadata_model.summary()\n",
        "combined_model.summary()\n",
        "\n",
        "print(train_X.shape)\n",
        "print(train_meta.shape)\n",
        "\n",
        "print(image_model.output_shape)\n",
        "print(metadata_model.output_shape)"
      ],
      "metadata": {
        "id": "6KWSmkxek_-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_combined_gen_shapes(train_X, train_meta, batch_size=32, num_batches=5):\n",
        "    num_samples = train_X.shape[0]\n",
        "    for i in range(num_batches):\n",
        "        start_idx = i * batch_size\n",
        "        end_idx = min((i+1) * batch_size, num_samples)\n",
        "        img_batch = train_X[start_idx:end_idx]\n",
        "        meta_batch = train_meta[start_idx:end_idx]\n",
        "        print(img_batch.shape, meta_batch.shape)\n",
        "# Print the shapes of the batches\n",
        "print_combined_gen_shapes(train_X, train_meta)\n"
      ],
      "metadata": {
        "id": "Eo-4rqqqobaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder()\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "categories = {}\n",
        "class_indices = {}\n",
        "\n",
        "def computing_class_weights(df, class_name):\n",
        "    class_labels = {name: index for index, name in enumerate(np.unique(df[class_name]))}\n",
        "    y_integers = np.array([class_labels[name] for name in df[class_name]])\n",
        "    weights = compute_sample_weight(class_weight='balanced', y=y_integers)\n",
        "\n",
        "    weight_dict = {}\n",
        "    for class_index in class_labels.values():\n",
        "        weight_dict[class_index] = weights[y_integers == class_index].mean()\n",
        "\n",
        "    return weight_dict\n",
        "\n",
        "def class_columns(df) :\n",
        "    return np.column_stack((np.asarray(df['subspecies']), np.asarray(df['health'])))\n",
        "\n",
        "def setup_onehot(df) :\n",
        "    # Fit one hot encoder\n",
        "    enc.fit(class_columns(df))\n",
        "    # Get categories\n",
        "    categories['subspecies'] = enc.categories_[0]\n",
        "    categories['health'] = enc.categories_[1]\n",
        "    # Get indices\n",
        "    class_indices['subspecies'] = np.arange(len(categories['subspecies']))\n",
        "    class_indices['health'] = len(categories['subspecies']) + np.arange(len(categories['health']))\n",
        "\n",
        "def onehot_encoding(df, class_name) :\n",
        "    if categories == {} :\n",
        "        raise ValueError('Run setup_onehot first')\n",
        "\n",
        "    return enc.transform(class_columns(df)).toarray()[:,class_indices[class_name]]\n",
        "\n",
        "def read_data() :\n",
        "    bees=pd.read_csv('./data/bees_train.csv',\n",
        "                index_col=False,\n",
        "                dtype={'subspecies':'category', 'health':'category','caste':'category'})\n",
        "    bees_test_for_evaluation=pd.read_csv('./data/bees_test.csv',\n",
        "                index_col=False,\n",
        "                dtype={'caste':'category'})\n",
        "\n",
        "    setup_onehot(bees)\n",
        "\n",
        "    class_weights = computing_class_weights(bees,'subspecies')\n",
        "\n",
        "    return bees, bees_test_for_evaluation, class_weights\n",
        "\n",
        "\n",
        "\n",
        "def eval_model(training, model, test_X, test_meta, test_y, field_name):\n",
        "    \"\"\"\n",
        "    Model evaluation: plots, classification report\n",
        "    @param training: model training history\n",
        "    @param model: trained model\n",
        "    @param test_X: features\n",
        "    @param test_y: labels\n",
        "    @param field_name: label name to display on plots\n",
        "    \"\"\"\n",
        "    ## Trained model analysis and evaluation\n",
        "    f, ax = plt.subplots(2,1, figsize=(5,5))\n",
        "    ax[0].plot(training.history['loss'], label=\"Loss\")\n",
        "    ax[0].plot(training.history['val_loss'], label=\"Validation loss\")\n",
        "    ax[0].set_title('%s: loss' % field_name)\n",
        "    ax[0].set_xlabel('Epoch')\n",
        "    ax[0].set_ylabel('Loss')\n",
        "    ax[0].legend()\n",
        "\n",
        "    # Accuracy\n",
        "    ax[1].plot(training.history['accuracy'], label=\"Accuracy\")\n",
        "    ax[1].plot(training.history['val_accuracy'], label=\"Validation accuracy\")\n",
        "    ax[1].set_title('%s: accuracy' % field_name)\n",
        "    ax[1].set_xlabel('Epoch')\n",
        "    ax[1].set_ylabel('Accuracy')\n",
        "    ax[1].legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Accuracy by category\n",
        "    # test_pred = model.predict(test_X)\n",
        "    test_pred = model.predict([test_X, test_meta])\n",
        "\n",
        "    acc_by_category = np.logical_and((test_pred > 0.5), test_y).sum()/test_y.sum()\n",
        "    acc_by_category.plot(kind='bar', title='Accuracy by %s' % field_name)\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()\n",
        "\n",
        "    # Print metrics\n",
        "    print(\"Classification report\")\n",
        "    # Print metrics\n",
        "    test_pred = np.argmax(test_pred, axis=1)\n",
        "    test_truth = np.argmax(test_y.values, axis=1)\n",
        "\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "        print(metrics.classification_report(test_truth, test_pred, target_names=categories[field_name]))\n",
        "\n",
        "    # Updated model evaluation to include test_meta\n",
        "    test_res = model.evaluate([test_X, test_meta], test_y.values, verbose=0)\n",
        "    print('Loss function: %s, accuracy:' % test_res[0], test_res[1])"
      ],
      "metadata": {
        "id": "L2YnLKFDr2iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, _, class_weights = read_data()\n",
        "class_weights"
      ],
      "metadata": {
        "id": "eZlcG1QzxAOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training, trained_model = train_with_metadata(\n",
        "    model=combined_model,\n",
        "    train_X=train_X,\n",
        "    train_y=train_y,\n",
        "    train_meta=train_meta,\n",
        "    val_meta=val_meta,\n",
        "    batch_size=10,\n",
        "    epochs=200,\n",
        "    validation_data_X=val_X,\n",
        "    validation_data_y=val_y,\n",
        "    steps_per_epoch=len(train_X) // 32,\n",
        "    rotation_range=90,\n",
        "    patience=5,\n",
        "    class_weights=class_weights\n",
        ")\n"
      ],
      "metadata": {
        "id": "Wyf59jGYjtba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "b096e119c62a41dc227ad9f12131ca0c28dbed8b",
        "id": "kfXFse3xr2on"
      },
      "outputs": [],
      "source": [
        "eval_model(training, trained_model, test_X, test_meta, test_y, 'subspecies')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### load_test\n",
        "img_folder='./data/imgs/'\n",
        "# Image processing\n",
        "import imageio\n",
        "import skimage\n",
        "import skimage.io\n",
        "import skimage.transform\n",
        "\n",
        "def read_img(file, img_folder, img_width, img_height, img_channels):\n",
        "    \"\"\"\n",
        "    Read and resize img, adjust channels.\n",
        "    @param file: file name without full path\n",
        "    \"\"\"\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "        img = skimage.io.imread(img_folder + file)\n",
        "        img = skimage.transform.resize(img, (img_width, img_height), mode='reflect', )\n",
        "    return img[:,:,:img_channels]\n",
        "\n",
        "def load_test(img_width, img_height, img_channels, encoder):\n",
        "    X_test_partition=pd.read_csv('./data/bees_test.csv', index_col=False, dtype={'caste':'category'})\n",
        "\n",
        "    print(\"X_test_partition shape:\", X_test_partition.shape)\n",
        "    print(\"X_test_partition columns:\", X_test_partition.columns)\n",
        "\n",
        "\n",
        "    test_images = np.stack(X_test_partition['file'].apply(lambda x: read_img(x, img_folder, img_width, img_height, img_channels)))\n",
        "\n",
        "    # preprocess metadata using the encoder\n",
        "    test_meta = preprocess_metadata(X_test_partition, encoder)\n",
        "\n",
        "    return X_test_partition, test_images, test_meta\n",
        "\n",
        "def predict_test(model, test_images, test_meta):\n",
        "\n",
        "    prob = model.predict([test_images, test_meta])\n",
        "    pred = np.argmax(prob, axis=1).reshape(-1,1)\n",
        "    return pred\n",
        "\n",
        "def gen_csv_file(test_ids, pred, class_name):\n",
        "    output = np.stack((test_ids, pred), axis=-1)\n",
        "    output = output.reshape([-1, 2])\n",
        "\n",
        "    df = pd.DataFrame(output)\n",
        "    df.columns = ['id','expected']\n",
        "\n",
        "    df['expected'] = df['expected'].map(pd.Series(categories[class_name]))\n",
        "    df.to_csv(\"test_\" + str(class_name) + \".csv\", index = False, index_label = False)\n",
        "    return df\n",
        "\n",
        "def load_test_and_generate_prediction_file(model, img_width, img_height, img_channels,encoder):\n",
        "    X_test_partition, test_images, test_meta = load_test(img_width, img_height, img_channels,encoder)\n",
        "    pred = predict_test(model, test_images, test_meta)\n",
        "\n",
        "    test_ids = X_test_partition['id']\n",
        "    test_ids = np.array(test_ids).reshape(-1,1)\n",
        "\n",
        "    return gen_csv_file(test_ids, pred, 'subspecies')\n"
      ],
      "metadata": {
        "id": "vxSlAH3syAf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HZta1rjU0Ysc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "id": "ISFXJDdS0Yyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir())\n",
        "os.chdir(\"./data/imgs\")\n",
        "print(os.listdir())\n",
        "os.chdir(\"../../\")"
      ],
      "metadata": {
        "id": "NgXxuL4k0Yyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_meta = test_meta.reshape(-1, 1) if test_meta.ndim == 1 else test_meta\n"
      ],
      "metadata": {
        "id": "QAv1CuMTMKCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_cols = set(train_meta.columns) - set(test_meta.columns)\n",
        "print(\"Missing columns:\", missing_cols)\n"
      ],
      "metadata": {
        "id": "iinp4aZ0Nvsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JBZwaUrQNvl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subspecies = load_test_and_generate_prediction_file(trained_model, img_width, img_height, img_channels, encoder)\n",
        "df_subspecies"
      ],
      "metadata": {
        "id": "MGG2tn6ur2on"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Bees_Template_Transfer_Learning.ipynb",
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}