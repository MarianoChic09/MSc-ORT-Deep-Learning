{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Pkg\n",
    "# Pkg.add(\"Flux\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: CUDA is on\n",
      "└ @ Main k:\\OneDrive\\Master en Big Data - Universidad ORT\\3er Semestre\\Deep Learning\\MSc-ORT-Deep-Learning\\Tarea 1\\Julia-Perceptron.ipynb:4\n"
     ]
    }
   ],
   "source": [
    "using CUDA\n",
    "\n",
    "if has_cuda()\t\t# Check if CUDA is available\n",
    "    @info \"CUDA is on\"\n",
    "    CUDA.allowscalar(false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux: params\n",
    "\n",
    "# using Flux: @epochs\n",
    "\n",
    "epochs = 5000\n",
    "\n",
    "# Datos de entrenamiento\n",
    "X = Float32[0 0; 0 1; 1 0; 1 1]'\n",
    "\n",
    "# Etiquetas combinadas (AND, OR, XOR, NOR, NAND)\n",
    "y_combined = Float32[0 0 0 1 1; 0 1 1 0 1; 0 1 1 0 1; 1 1 0 0 0]'\n",
    "\n",
    "# Definición del modelo\n",
    "model = Chain(\n",
    "    Dense(2, 10, σ),  # Capa oculta con 10 neuronas\n",
    "    Dense(10, 5, σ)   # Capa de salida con 5 neuronas (AND, OR, XOR, NOR, NAND)\n",
    ")\n",
    "\n",
    "# Función de pérdida\n",
    "loss(x, y) = Flux.Losses.logitbinarycrossentropy(model(x), y)\n",
    "\n",
    "# Optimizador\n",
    "opt = ADAM()\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "for epoch in 1:epochs\n",
    "    if epoch % 1000 == 0\n",
    "        @info \"Epoch $epoch\"\n",
    "    end\n",
    "    Flux.train!(loss, params(model), [(X, y_combined)], opt)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "predictions = model(X)\n",
    "println(round.(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, definiremos la función de activación signo e implementaremos el perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "perceptron (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "sign_activation(x) = x >= 0 ? 1 : -1\n",
    "\n",
    "function perceptron(X, W, b)\n",
    "    return sign_activation(dot(X, W) + b)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, definiremos los pesos y sesgos para las funciones booleanas AND, OR, NOR y NAND:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pesos y sesgos\n",
    "W_and = [0.5, 0.5]\n",
    "b_and = -0.7\n",
    "\n",
    "W_or = [0.5, 0.5]\n",
    "b_or = -0.2\n",
    "\n",
    "W_nor = [-0.5, -0.5]\n",
    "b_nor = 0.2\n",
    "\n",
    "W_nand = [-0.5, -0.5]\n",
    "b_nand = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, probaremos el perceptrón con las diferentes combinaciones de entrada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0, 0] -> -1\n",
      "[0, 1] -> -1\n",
      "[1, 0] -> -1\n",
      "[1, 1] -> 1\n",
      "\n",
      "OR:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0, 0] -> -1\n",
      "[0, 1] -> 1\n",
      "[1, 0] -> 1\n",
      "[1, 1] -> 1\n",
      "\n",
      "NOR:\n",
      "[0, 0] -> 1\n",
      "[0, 1] -> -1\n",
      "[1, 0] -> -1\n",
      "[1, 1] -> -1\n",
      "\n",
      "NAND:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0, 0] -> 1\n",
      "[0, 1] -> 1\n",
      "[1, 0] -> 1\n",
      "[1, 1] -> -1\n"
     ]
    }
   ],
   "source": [
    "println(\"AND:\")\n",
    "for x in [Vector(r) for r in eachrow(inputs)]\n",
    "    println(x, \" -> \", perceptron(x, W_and, b_and))\n",
    "end\n",
    "\n",
    "println(\"\\nOR:\")\n",
    "for x in [Vector(r) for r in eachrow(inputs)]\n",
    "    println(x, \" -> \", perceptron(x, W_or, b_or))\n",
    "end\n",
    "\n",
    "println(\"\\nNOR:\")\n",
    "for x in [Vector(r) for r in eachrow(inputs)]\n",
    "    println(x, \" -> \", perceptron(x, W_nor, b_nor))\n",
    "end\n",
    "\n",
    "println(\"\\nNAND:\")\n",
    "for x in [Vector(r) for r in eachrow(inputs)]\n",
    "    println(x, \" -> \", perceptron(x, W_nand, b_nand))\n",
    "end\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
