{"cells":[{"cell_type":"markdown","metadata":{"id":"SFDq4IxV9kjk"},"source":["# Mi primera red neuronal"]},{"cell_type":"markdown","metadata":{"id":"eURfGgTu9kjm"},"source":["$$\n","\\mathcal{P}(x; w) = sgn(x\\, w) = sgn\\left( \\sum_i x_i w_i \\right) \n","\\quad x, w \\in \\mathbb{R}^m\n","$$\n","con\n","$$\n"," sgn(u) = \n","  \\begin{cases} \n","   +1 & \\text{if } u \\geq 0 \\\\\n","   -1 & \\text{if } u < 0\n","  \\end{cases}\n","$$\t"]},{"cell_type":"markdown","metadata":{"id":"F8h6NsrG9kjn"},"source":["En forma vectorial\n","\n","$$\\mathcal{P}(X; W) = sgn\\left( X \\, W \\right) \\quad X \\in \\mathbb{R}^{(n,m)}, \\, W \\in \\mathbb{R}^{(m,1)}$$\n"]},{"cell_type":"markdown","metadata":{"id":"h0oBYiBO9kjn"},"source":["## Ejemplo: AND\n","\n","$$\n","X = \\begin{pmatrix}\n","  0 & 0 & 1 \\\\\n","  0 & 1 & 1 \\\\\n","  1 & 0 & 1 \\\\\n","  1 & 1 & 1 \\\\\n"," \\end{pmatrix}\n","\\qquad\n","\\textbf{AND}\\left( X \\right) = \n"," \\begin{pmatrix}\n","  -1 \\\\\n","  -1 \\\\\n","  -1 \\\\\n","  1  \\\\\n"," \\end{pmatrix}\n","\\qquad\n","n = 4\n","$$"]},{"cell_type":"markdown","metadata":{"id":"jPwofV509kjo"},"source":["$$\n","\\textbf{AND}\\left(X \\right) = sgn\\left( X \\,   \n","    \\begin{pmatrix}\n","      .5 \\\\\n","      .5 \\\\\n","      -1 \\\\\n","    \\end{pmatrix} \\right)\n","    \\quad\n","    m = 3\n","$$"]},{"cell_type":"markdown","metadata":{"id":"dMJawwz89kjp"},"source":["### En python"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"G1DkRxyn9kjq"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"I3Bg5oNB9kjq"},"outputs":[],"source":["# Signo de un numero\n","def _sgn(u) : return 1 if u >= 0 else -1\n","\n","# Signo de un tensor\n","def sgn(t) : return (np.vectorize(_sgn))(t)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"ZCiCxwW19kjr"},"outputs":[],"source":["# X es una matriz de shape = (4, 3)\n","X = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]])"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"j9VkLLUF9kjr","outputId":"395ff924-cd99-4268-f55c-5ae1aec83976"},"outputs":[{"data":{"text/plain":["array([[0, 0, 1],\n","       [0, 1, 1],\n","       [1, 0, 1],\n","       [1, 1, 1]])"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["X"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"Ss96RHxF9kjs","outputId":"5feb519f-3011-4490-f17a-a153fbdc0bed"},"outputs":[{"data":{"text/plain":["(4, 3)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["X.shape"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["array([[ 0.5],\n","       [ 0.5],\n","       [-1. ]])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["np.array([.5, .5, -1]).reshape((3,1))"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"kyNdDW9B9kjs"},"outputs":[],"source":["def AND(X) : \n","    W = np.array([.5, .5, -1]).reshape((3,1))\n","    return sgn(np.matmul(X, W))"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"wprwAxeX9kjt","outputId":"f0f1acf7-cab0-464a-b43a-bbac25ffe716"},"outputs":[{"data":{"text/plain":["array([[-1],\n","       [-1],\n","       [-1],\n","       [ 1]])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["AND(X)"]},{"cell_type":"markdown","metadata":{"id":"6V9D0lBD9kjt"},"source":["##   Implementar AND de la forma X W + b"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"CeMh6M9cDQOu"},"outputs":[],"source":["# X es una matriz de shape = (4, 2)\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"yl5VisVT_0lM"},"outputs":[],"source":["def AND(X) : \n","  W = np.array([.5, .5]).reshape((2,1))\n","  b = -1\n","  return sgn(np.matmul(X, W) + b)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["array([[-1],\n","       [-1],\n","       [-1],\n","       [ 1]])"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["AND(X)"]},{"cell_type":"markdown","metadata":{"id":"NpphB9KS-Wbi"},"source":["# Tarea 1\n","\n","\n","\n","* **Ejercicio 1**: Utilizando como base el perceptron visto en clase para modelar la función booleana AND, implementar un perceptrón en python para las funciones booleanas definidas en las diapositvas de clase. En caso de no ser posible hacerlo con un perceptron indíquelo y justifique.\n","\n","  **Ayuda**: Sólo hay que encontrar para cada función booleana el vector de pesos W. La estructura del perceptron y la función de activación son las mismas que las usadas en clase para implementar AND.\n","\n","\n","+\n","\n","* **Ejercicio 2**: \n","Implementar una red neuronal densa en python que compute simultáneamente todas las funciones booleanas implementadas.\n","\n","  **Ayuda**: El shape del resultado tiene que ser (,k) dónde k es la cantidad de funciones booleanas implementadas.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### NAND"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"V41A3Zh_-NiB"},"outputs":[{"data":{"text/plain":["array([[ 1],\n","       [ 1],\n","       [ 1],\n","       [-1]])"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["# NAND = [1,1,1,-1]\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","\n","def NAND(X) : \n","  W = np.array([-.5, -.5]).reshape((2,1))\n","  b = 0.5\n","  return sgn(np.matmul(X, W) + b)\n","\n","NAND(X)"]},{"cell_type":"markdown","metadata":{},"source":["### OR"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["array([[-1],\n","       [ 1],\n","       [ 1],\n","       [ 1]])"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["# OR = [-1,1,1,1]\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","\n","def OR(X) : \n","  W = np.array([.5, .5]).reshape((2,1))\n","  b = -0.5\n","  return sgn(np.matmul(X, W) + b)\n","\n","OR(X)"]},{"cell_type":"markdown","metadata":{},"source":["### NOR"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/plain":["array([[ 1],\n","       [-1],\n","       [-1],\n","       [-1]])"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["# NOR = [1,-1,-1,-1]\n","\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","\n","def NOR(X) : \n","  W = np.array([-2, -2]).reshape((2,1))\n","  b = 1\n","  return sgn(np.matmul(X, W) + b)\n","\n","NOR(X)"]},{"cell_type":"markdown","metadata":{},"source":["### XOR"]},{"cell_type":"markdown","metadata":{},"source":["La funcion XOR no puede ser modelada por un solo perceptrón porque no es linealmente separable, esto significa que no se puede trazar una sola línea recta (o plano, o hiperplano) para separar salidas 1 de las 0. "]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/plain":["array([[-1],\n","       [ 1],\n","       [ 1],\n","       [-1]])"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["# XOR = [-1,1,1,-1]\n","\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","\n","def XOR(X) :\n","    return AND(np.concatenate((NAND(X), OR(X)), axis=1))\n","\n","XOR(X)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Ejercicio 2"]},{"cell_type":"markdown","metadata":{},"source":["Implemento una red neuronal multicapa para implementar todas las compuertas. \n","\n","Para esto: \n","\n","1. Defino los datos de entrenamiento en *X* es decir todas las combinaciones de dos valores booleanos: (0,0), (0,1), (1,0) y (1,1). \n","2. Armo las etiquetas combinadas en *y*. Esto representa las etiquetas de salida para las cinco funciones booleanas que implementé: AND, OR, XOR, NOR y NAND. \n","    - AND = [0,0,0,1]\n","    - OR = [0,1,1,1]\n","    - XOR = [0,1,1,0]\n","    - NOR = [1,0,0,0]\n","    - NAND = [1,1,1,0]\n","3. Armo la red neuronal multicapa: Usando *Sequential* de Keras. El shape de entrada es (4,2) por las 4 combinaciones posibles de valores booleanos y cada combinación es de dos valores. Agrego una capa oculta de 10 neuronas y la combinación tiene un shape de salida de (,5) para la salida correspondiente a las 5 funciones booleanas que se implementaron. \n","4. Se utiliza la función de activación *sigmoide* porque queremos que las salida sean 0 o 1. \n","5. Utilizo la función de pérdida *binary_crossentropy* y el optimizador *adam*. \n","6. Entreno el algoritmo usando *model.fit()* con 5000 epochs.\n","7. Se toman predicciones para mostrar el resultado. "]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B4B8E1AEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","1/1 [==============================] - 0s 72ms/step\n","[[0. 0. 0. 1. 1.]\n"," [0. 1. 1. 0. 1.]\n"," [0. 1. 1. 0. 1.]\n"," [1. 1. 0. 0. 0.]]\n"]}],"source":["import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense\n","\n","# Datos de entrenamiento\n","X = np.array([[0,0], [0,1], [1,0], [1,1]]) # Shape = (4,2) por cada combinación de valores de entrada (0,0), (0,1), (1,0), (1,1)\n","\n","# Etiquetas combinadas (AND, OR, XOR, NOR, NAND) - > Por lo tanto voy a tener un shape de salida (,5)\n","# AND = [0,0,0,1]\n","# OR = [0,1,1,1]\n","# XOR = [0,1,1,0]\n","# NOR = [1,0,0,0]\n","# NAND = [1,1,1,0]\n","\n","y = np.array([[0, 0, 0, 1, 1], [0, 1, 1, 0, 1], [0, 1, 1, 0, 1], [1, 1, 0, 0, 0]])\n","\n","model = Sequential()\n","model.add(Dense(10, input_dim=2, activation='sigmoid'))  # Capa oculta con 10 neuronas\n","model.add(Dense(5, activation='sigmoid'))  # Capa de salida con 5 neuronas (AND, OR, XOR, NOR, NAND)\n","\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit(X, y, epochs=5000, verbose=0)\n","\n","predictions = model.predict(X)\n","print(predictions.round())\n"]},{"cell_type":"markdown","metadata":{},"source":["AND = [0,0,0,1]\n","\n","OR = [0,1,1,1]\n","\n","XOR = [0,1,1,0]\n","\n","NOR = [1,0,0,0]\n","\n","NAND = [1,1,1,0]"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["AND:  [0. 0. 0. 1.]\n","OR:  [0. 1. 1. 1.]\n","XOR:  [0. 1. 1. 0.]\n","NOR:  [1. 0. 0. 0.]\n","NAND:  [1. 1. 1. 0.]\n","AND:  [1.7807300e-06 7.8892028e-03 7.0497054e-03 9.8171276e-01]\n","OR:  [0.01406255 0.9894282  0.9881289  0.9997933 ]\n","XOR:  [0.0435443  0.9624294  0.96156013 0.0504291 ]\n","NOR:  [9.8832160e-01 8.4823109e-03 9.8067196e-03 2.2725778e-04]\n","NAND:  [0.99999994 0.99670076 0.99731326 0.00710872]\n"]}],"source":["AND_result = predictions[:,0]\n","OR_result = predictions[:,1]\n","XOR_result = predictions[:,2]\n","NOR_result = predictions[:,3]\n","NAND_result = predictions[:,4]\n","print(\"AND: \",AND_result.round())\n","print(\"OR: \",OR_result.round())\n","print(\"XOR: \",XOR_result.round())\n","print(\"NOR: \",NOR_result.round())\n","print(\"NAND: \",NAND_result.round())\n"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["AND:  [1.7807300e-06 7.8892028e-03 7.0497054e-03 9.8171276e-01]\n","OR:  [0.01406255 0.9894282  0.9881289  0.9997933 ]\n","XOR:  [0.0435443  0.9624294  0.96156013 0.0504291 ]\n","NOR:  [9.8832160e-01 8.4823109e-03 9.8067196e-03 2.2725778e-04]\n","NAND:  [0.99999994 0.99670076 0.99731326 0.00710872]\n"]}],"source":["# Sin round\n","\n","print(\"AND: \",AND_result)\n","print(\"OR: \",OR_result)\n","print(\"XOR: \",XOR_result)\n","print(\"NOR: \",NOR_result)\n","print(\"NAND: \",NAND_result)\n"]}],"metadata":{"celltoolbar":"Slideshow","colab":{"collapsed_sections":[],"name":"Perceptron.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":0}
